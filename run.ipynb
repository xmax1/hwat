{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init sub classes\n",
      "updating configuration\n",
      "Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n",
      "stdout: 61fc966 stderr: \n",
      "Run: ['hostname'] at .\n",
      "stdout: oceanus  stderr: \n",
      "running script\n",
      "setting exp_path\n",
      "Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n",
      "stdout: 61fc966 stderr: \n",
      "Run: ['hostname'] at .\n",
      "stdout: oceanus  stderr: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxmax1\u001b[0m (\u001b[33mhwat\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>dump/exp/junk-22/ZPAVami/wandb/run-20221224_130755-2wrldy2h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hwat/hwat/runs/2wrldy2h\" target=\"_blank\">volcanic-yogurt-176</a></strong> to <a href=\"https://wandb.ai/hwat/hwat\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ 1 GPUs available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' copy lines and run in analysis while the exp is live '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Distribution ‚ú® ‚ùá Demo üí™ ### \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "### fancy logging variables, philosophically reminding us of the goal ###\n",
    "fancy = dict(\n",
    "\t\tpe\t\t= r'$V(X)',    \t\t\t\t\n",
    "\t\tke\t\t= r'$\\nabla^2',    \t\t\n",
    "\t\te\t\t= r'$E',\t\t\t\t\t\t\n",
    "\t\tlog_psi\t= r'$\\log\\psi', \t\t\t\n",
    "\t\tdeltar\t= r'$\\delta_\\mathrm{r}',\t\n",
    "\t\tx\t\t= r'$r_\\mathrm{e}',\n",
    ")\n",
    "\n",
    "### pyfig ###\n",
    "from pyfig import Pyfig\n",
    "\n",
    "# arg = {\n",
    "# \t'a_z':[4,], \n",
    "# \t'n_b': 256, \n",
    "# \t'n_sv': 16, \n",
    "# \t'n_pv': 16, \n",
    "# \t'n_corr': 20, \n",
    "# \t'n_step': 100000, \n",
    "# \t'log_metric_step': 1, \n",
    "# \t'exp_name':'demo',\n",
    "# }\n",
    "\n",
    "c = Pyfig(wb_mode='online', submit=False, run_sweep=False, notebook=True)\n",
    "\n",
    "n_device = c.n_device\n",
    "print(f'ü§ñ {n_device} GPUs available')\n",
    "\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(c.d)\n",
    "\n",
    "\"\"\" live plotting in another notebook \"\"\"\n",
    "\"\"\" copy lines and run in analysis while the exp is live \"\"\"\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<run-here>\")\n",
    "# c = run.config\n",
    "# h = run.history()\n",
    "# s = run.summary\n",
    "\n",
    "\n",
    "# SOLVE THE CONUNDRUM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:  cuda n_dev:  1 device cuda name:  NVIDIA TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1234)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)   # ‚ùó Ensure works when default not set AND can go float32 or 64\n",
    "n_device = torch.cuda.device_count()\n",
    "current_device = torch.cuda.current_device()\n",
    "device = torch.cuda.device(0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "print('cuda: ', device, 'n_dev: ', n_device, 'device', device, 'name: ', device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r:  torch.Size([1, 256, 4, 3]) torch.float64\n",
      "Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n",
      "stdout: 61fc966 stderr: \n",
      "Run: ['hostname'] at .\n",
      "stdout: oceanus  stderr: \n",
      "anti-symmetry:  -13.849039612827461 -13.849039612827461 1.0 -1.0\n",
      "anti-symmetry:  -13.849039612827461 -13.849039612827461 1.0 -1.0\n",
      "Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n",
      "stdout: 61fc966 stderr: \n",
      "Run: ['hostname'] at .\n",
      "stdout: oceanus  stderr: \n",
      "{'TMP': PosixPath('dump/tmp'),\n",
      " 'cap': 3,\n",
      " 'commit_id': '61fc966',\n",
      " 'data': {'a': tensor([[0., 0., 0.]], device='cuda:0'),\n",
      "          'a_z': tensor([4.], device='cuda:0'),\n",
      "          'acc_target': 0.5,\n",
      "          'charge': 0,\n",
      "          'n_b': 256,\n",
      "          'n_corr': 20,\n",
      "          'n_d': 2,\n",
      "          'n_e': 4,\n",
      "          'n_equil': 10000,\n",
      "          'n_u': 2,\n",
      "          'spin': 0},\n",
      " 'debug': False,\n",
      " 'dtype': 'float32',\n",
      " 'dump': PosixPath('dump'),\n",
      " 'env': 'lumi',\n",
      " 'exp_name': 'junk',\n",
      " 'exp_path': PosixPath('dump/exp/junk-22/ZPAVami'),\n",
      " 'git_branch': 'main',\n",
      " 'git_remote': 'origin',\n",
      " 'hostname': 'oceanus ',\n",
      " 'log_metric_step': 10,\n",
      " 'log_state_step': 10,\n",
      " 'model': {'n_det': 1,\n",
      "           'n_fb': 3,\n",
      "           'n_fbv': 128,\n",
      "           'n_pv': 16,\n",
      "           'n_sv': 32,\n",
      "           'terms_p_emb': ['rr', 'rr_len'],\n",
      "           'terms_s_emb': ['ra', 'ra_len'],\n",
      "           'with_sign': False},\n",
      " 'n_device': 1,\n",
      " 'n_step': 10000,\n",
      " 'project': 'hwat',\n",
      " 'project_dir': PosixPath('/home/amawi/projects/hwat'),\n",
      " 'run_dir': PosixPath('projects/hwat'),\n",
      " 'run_name': 'run.py',\n",
      " 'run_sweep': False,\n",
      " 'sbatch': 'module purge\\n'\n",
      "           'source ~/.bashrc\\n'\n",
      "           'module load GCC\\n'\n",
      "           'module load CUDA/11.4.1\\n'\n",
      "           'module load cuDNN/8.2.2.26-CUDA-11.4.1\\n'\n",
      "           'conda activate lumi',\n",
      " 'seed': 808017424,\n",
      " 'server': 'svol.fysik.dtu.dk',\n",
      " 'server_project_dir': PosixPath('projects/hwat'),\n",
      " 'slurm': {'cpus_per_task': 1,\n",
      "           'error': PosixPath('dump/exp/junk-22/ZPAVami/e-%j.err'),\n",
      "           'gres': 'gpu:RTX3090:1',\n",
      "           'job_name': 'junk',\n",
      "           'mail_type': 'FAIL',\n",
      "           'nodes': 1,\n",
      "           'ntasks': 8,\n",
      "           'output': PosixPath('dump/exp/junk-22/ZPAVami/o-%j.out'),\n",
      "           'partition': 'sm3090',\n",
      "           'time': '0-12:00:00'},\n",
      " 'submit': False,\n",
      " 'sweep': {'method': 'grid',\n",
      "           'name': 'demo',\n",
      "           'parameters': {'n_b': {'values': [16, 32, 64]}}},\n",
      " 'sweep_id': '',\n",
      " 'sweep_path_id': '',\n",
      " 'user': 'amawi',\n",
      " 'wandb_c': {'entity': 'hwat',\n",
      "             'job_type': 'training',\n",
      "             'name': 'junk',\n",
      "             'program': PosixPath('projects/hwat/run.py')},\n",
      " 'wb_mode': 'online'}\n"
     ]
    }
   ],
   "source": [
    "### model ###\n",
    "from functools import partial\n",
    "from hwat_func import Ansatz_fb\n",
    "from torch import nn\n",
    "\n",
    "import pprint\n",
    "\n",
    "from hwat_func import init_r, get_center_points\n",
    "\n",
    "dtype = torch.randn(1).dtype\n",
    "c._convert(device, dtype=dtype)\n",
    "\n",
    "n_e = c.data.n_e\n",
    "center_points = get_center_points(c.data.n_e, c.data.a)\n",
    "r = init_r(n_device, c.data.n_b, c.data.n_e, center_points, std=0.1).to(device)\n",
    "dtype = r.dtype\n",
    "\n",
    "print('r: ', r.shape, r.dtype)\n",
    "r = r[0]  # single batch, single gpu, ‚ùó how to multi gpu\n",
    "\n",
    "model_check = c.partial(Ansatz_fb, with_sign=True).to(device)\n",
    "r_swap = r[0, [1,0]+[i for i in range(2, c.data.n_e)]]\n",
    "lp0, s0 = model_check(r[0])\n",
    "lp1, s1 = model_check(r_swap)\n",
    "print('anti-symmetry: ', lp0.item(), lp0.item(), s0.item(), s1.item())\n",
    "r_swap = r[0, [i for i in range(0, c.data.n_e-2)]+[n_e-1,n_e-2]]\n",
    "lp1, s1 = model_check(r_swap)\n",
    "print('anti-symmetry: ', lp0.item(), lp0.item(), s0.item(), s1.item())\n",
    "\n",
    "pprint.pprint(c.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp/actual | \n",
      "\tcps    : (4, 3)/torch.Size([4, 3])\n",
      "\tr      : (1, 256, 4, 3)/torch.Size([256, 4, 3])\n",
      "\tdeltar : (1,)/torch.Size([1])\n",
      "\n",
      "Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n",
      "stdout: 61fc966 stderr: \n",
      "Run: ['hostname'] at .\n",
      "stdout: oceanus  stderr: \n",
      "Go see: https://wandb.ai/hwat/hwat/runs/2wrldy2h\n",
      "tensor(509.2230, device='cuda:0')\n",
      "tensor([[ 0.5171,  1.0603, -0.1723],\n",
      "        [ 0.5839, -0.3778,  0.1429]], device='cuda:0')\n",
      "{'e': '-9.3907', 'ke': '10.7113', 'pe': '-20.1020', 'r': '0.0012', 'step': 12}\n",
      "tensor(897.5371, device='cuda:0')\n",
      "tensor([[-0.0759,  0.6830,  0.2188],\n",
      "        [ 0.4435,  0.1417, -1.6433]], device='cuda:0')\n",
      "{'e': '-7.6689', 'ke': '5.8439', 'pe': '-13.5127', 'r': '0.0152', 'step': 24}\n",
      "tensor(1329.7654, device='cuda:0')\n",
      "tensor([[ 0.1794,  1.5380,  0.5838],\n",
      "        [-0.7234, -0.7959, -1.2386]], device='cuda:0')\n",
      "{'e': '-8.1272', 'ke': '6.2192', 'pe': '-14.3464', 'r': '0.0238', 'step': 39}\n",
      "tensor(1522.1978, device='cuda:0')\n",
      "tensor([[-0.3311, -0.2237, -0.1003],\n",
      "        [-1.0535, -0.4163,  0.4139]], device='cuda:0')\n",
      "{'e': '-7.2412', 'ke': '6.0762', 'pe': '-13.3174', 'r': '0.0501', 'step': 53}\n",
      "tensor(1203.1511, device='cuda:0')\n",
      "tensor([[-0.9528,  1.4192, -0.6716],\n",
      "        [-0.2732, -0.1553,  0.2064]], device='cuda:0')\n",
      "{'e': '-7.9550', 'ke': '5.9711', 'pe': '-13.9261', 'r': '0.0365', 'step': 66}\n",
      "tensor(1292.6386, device='cuda:0')\n",
      "tensor([[ 0.5624, -1.0353, -0.7071],\n",
      "        [ 0.4691,  0.1505, -0.3214]], device='cuda:0')\n",
      "{'e': '-7.3138', 'ke': '6.3243', 'pe': '-13.6381', 'r': '0.0070', 'step': 79}\n",
      "tensor(1378.3628, device='cuda:0')\n",
      "tensor([[ 1.0854, -0.7107,  0.1765],\n",
      "        [ 1.4128,  0.7754,  0.1615]], device='cuda:0')\n",
      "{'e': '-7.3630', 'ke': '6.2622', 'pe': '-13.6252', 'r': '0.0077', 'step': 91}\n",
      "tensor(1556.7734, device='cuda:0')\n",
      "tensor([[-0.1855, -1.1329,  0.5103],\n",
      "        [ 0.2312,  1.1737,  0.2011]], device='cuda:0')\n",
      "{'e': '-5.7729', 'ke': '8.5782', 'pe': '-14.3511', 'r': '0.0149', 'step': 104}\n",
      "tensor(1694.7085, device='cuda:0')\n",
      "tensor([[ 0.0695,  0.6477, -0.9249],\n",
      "        [-0.9905,  0.4550, -0.3123]], device='cuda:0')\n",
      "{'e': '-7.6224', 'ke': '5.6223', 'pe': '-13.2447', 'r': '0.0272', 'step': 117}\n",
      "tensor(1629.1232, device='cuda:0')\n",
      "tensor([[-0.7823, -0.5279,  1.2786],\n",
      "        [ 0.0253,  0.9431, -0.0075]], device='cuda:0')\n",
      "{'e': '-6.6863', 'ke': '6.3275', 'pe': '-13.0138', 'r': '0.0311', 'step': 129}\n",
      "tensor(1755.1567, device='cuda:0')\n",
      "tensor([[-0.6253,  0.2260,  0.0883],\n",
      "        [-0.0421,  0.2968, -0.9726]], device='cuda:0')\n",
      "{'e': '-14.4273', 'ke': '-1.0120', 'pe': '-13.4153', 'r': '0.0187', 'step': 141}\n",
      "tensor(1870.6630, device='cuda:0')\n",
      "tensor([[ 0.3148,  1.4438,  0.3772],\n",
      "        [-0.5032, -0.7905,  0.5554]], device='cuda:0')\n",
      "{'e': '-7.0958', 'ke': '5.8648', 'pe': '-12.9605', 'r': '0.0380', 'step': 154}\n",
      "tensor(1938.8824, device='cuda:0')\n",
      "tensor([[ 0.3399,  0.5190, -1.7011],\n",
      "        [-0.1973,  0.0945,  0.5493]], device='cuda:0')\n",
      "{'e': '0.1720', 'ke': '13.4945', 'pe': '-13.3225', 'r': '0.0217', 'step': 171}\n",
      "tensor(2052.2259, device='cuda:0')\n",
      "tensor([[-0.5520, -0.5652, -0.2128],\n",
      "        [-1.6747,  0.1369,  0.3996]], device='cuda:0')\n",
      "{'e': '-7.3161', 'ke': '5.7182', 'pe': '-13.0344', 'r': '0.0397', 'step': 184}\n",
      "tensor(1890.8861, device='cuda:0')\n",
      "tensor([[ 1.6059,  0.5395, -0.2417],\n",
      "        [-0.8810, -0.2944,  0.7825]], device='cuda:0')\n",
      "{'e': '-6.7195', 'ke': '6.6248', 'pe': '-13.3444', 'r': '0.0178', 'step': 197}\n",
      "tensor(2246.9353, device='cuda:0')\n",
      "tensor([[ 0.7381,  1.2116, -1.3640],\n",
      "        [-0.1547,  0.0915,  1.1214]], device='cuda:0')\n",
      "{'e': '-7.1216', 'ke': '3.6198', 'pe': '-10.7414', 'r': '0.0388', 'step': 210}\n",
      "tensor(2190.3888, device='cuda:0')\n",
      "tensor([[ 1.0745,  1.8560,  0.2924],\n",
      "        [ 0.0306, -1.0947,  1.6368]], device='cuda:0')\n",
      "{'e': '-7.3758', 'ke': '4.0187', 'pe': '-11.3945', 'r': '0.0461', 'step': 223}\n",
      "tensor(2374.4299, device='cuda:0')\n",
      "tensor([[-0.9127, -1.6039, -0.4637],\n",
      "        [-0.8897,  1.1876,  0.1591]], device='cuda:0')\n",
      "{'e': '-7.3216', 'ke': '3.8925', 'pe': '-11.2142', 'r': '0.0511', 'step': 235}\n",
      "tensor(2420.6855, device='cuda:0')\n",
      "tensor([[-1.8152, -1.4799, -0.1564],\n",
      "        [ 0.5399,  0.1850, -0.5818]], device='cuda:0')\n",
      "{'e': '-7.0246', 'ke': '3.9853', 'pe': '-11.0099', 'r': '0.0487', 'step': 247}\n",
      "tensor(2436.9029, device='cuda:0')\n",
      "tensor([[ 0.0340, -2.3106, -0.2893],\n",
      "        [ 1.0401,  0.8300,  0.6571]], device='cuda:0')\n",
      "{'e': '-7.2766', 'ke': '3.6815', 'pe': '-10.9581', 'r': '0.0180', 'step': 259}\n",
      "tensor(2460.1919, device='cuda:0')\n",
      "tensor([[ 0.9646,  2.0734, -0.4424],\n",
      "        [-3.1316,  0.1891, -0.2745]], device='cuda:0')\n",
      "{'e': '-6.8621', 'ke': '3.4338', 'pe': '-10.2959', 'r': '-0.0192', 'step': 271}\n",
      "tensor(2365.5666, device='cuda:0')\n",
      "tensor([[ 0.7420,  1.1749, -1.0712],\n",
      "        [-0.1292, -2.2035, -0.5708]], device='cuda:0')\n",
      "{'e': '-6.8881', 'ke': '3.7636', 'pe': '-10.6516', 'r': '0.0547', 'step': 283}\n",
      "tensor(2405.9011, device='cuda:0')\n",
      "tensor([[-0.9821, -1.0334,  0.6061],\n",
      "        [ 0.0649,  0.5774,  1.1620]], device='cuda:0')\n",
      "{'e': '-7.0238', 'ke': '3.7247', 'pe': '-10.7485', 'r': '0.0059', 'step': 296}\n",
      "tensor(2583.4547, device='cuda:0')\n",
      "tensor([[-0.1913, -0.1655,  0.9845],\n",
      "        [-2.1543, -0.2205,  1.1408]], device='cuda:0')\n",
      "{'e': '-7.1419', 'ke': '3.6270', 'pe': '-10.7690', 'r': '0.0077', 'step': 310}\n",
      "tensor(2486.4743, device='cuda:0')\n",
      "tensor([[ 1.0932, -1.0711, -1.8979],\n",
      "        [-0.4471, -0.3710,  1.1381]], device='cuda:0')\n",
      "{'e': '-7.3916', 'ke': '3.7674', 'pe': '-11.1589', 'r': '0.0279', 'step': 323}\n",
      "tensor(2579.5037, device='cuda:0')\n",
      "tensor([[ 1.1588,  0.6219,  0.7822],\n",
      "        [-0.3597, -1.2444,  0.7835]], device='cuda:0')\n",
      "{'e': '-6.7565', 'ke': '3.4229', 'pe': '-10.1794', 'r': '0.0353', 'step': 335}\n",
      "tensor(2596.3284, device='cuda:0')\n",
      "tensor([[ 1.3713,  0.1851,  1.0010],\n",
      "        [-0.1002, -0.8065,  0.4445]], device='cuda:0')\n",
      "{'e': '-7.3228', 'ke': '3.6200', 'pe': '-10.9428', 'r': '0.0015', 'step': 347}\n",
      "tensor(2561.4465, device='cuda:0')\n",
      "tensor([[ 0.6103, -0.5563, -1.4465],\n",
      "        [-1.5984, -0.8583,  1.0106]], device='cuda:0')\n",
      "{'e': '-7.5746', 'ke': '3.7805', 'pe': '-11.3550', 'r': '0.0050', 'step': 359}\n",
      "tensor(2348.3194, device='cuda:0')\n",
      "tensor([[ 0.9380,  1.6953,  1.5605],\n",
      "        [-0.6764,  0.0522,  0.1755]], device='cuda:0')\n",
      "{'e': '-7.1794', 'ke': '3.7442', 'pe': '-10.9236', 'r': '0.0501', 'step': 371}\n",
      "tensor(2383.0511, device='cuda:0')\n",
      "tensor([[ 4.9926,  3.8538, -0.7736],\n",
      "        [-1.3768,  0.5119, -0.7863]], device='cuda:0')\n",
      "{'e': '-7.3841', 'ke': '3.5984', 'pe': '-10.9825', 'r': '0.0459', 'step': 384}\n",
      "tensor(2465.0562, device='cuda:0')\n",
      "tensor([[-1.8471,  0.8282, -0.4145],\n",
      "        [-0.3197,  0.2540,  0.2343]], device='cuda:0')\n",
      "{'e': '-7.2289', 'ke': '3.8318', 'pe': '-11.0607', 'r': '0.0142', 'step': 398}\n",
      "tensor(2245.4766, device='cuda:0')\n",
      "tensor([[-2.2495, -1.5580, -1.3596],\n",
      "        [-0.5837,  0.8409, -1.1910]], device='cuda:0')\n",
      "{'e': '-7.2477', 'ke': '4.0623', 'pe': '-11.3100', 'r': '0.0406', 'step': 412}\n",
      "tensor(2339.2709, device='cuda:0')\n",
      "tensor([[-1.2377, -0.4001, -0.4896],\n",
      "        [ 0.8781,  2.1676, -0.6022]], device='cuda:0')\n",
      "{'e': '-7.2535', 'ke': '3.5337', 'pe': '-10.7872', 'r': '0.0292', 'step': 427}\n",
      "tensor(2334.5333, device='cuda:0')\n",
      "tensor([[-1.6010, -2.0666, -0.6675],\n",
      "        [-0.2116,  1.6742,  0.1687]], device='cuda:0')\n",
      "{'e': '-7.6573', 'ke': '3.9535', 'pe': '-11.6108', 'r': '0.0186', 'step': 439}\n",
      "tensor(2332.2085, device='cuda:0')\n",
      "tensor([[ 0.4396, -0.3805, -1.0251],\n",
      "        [ 1.7306,  2.2880, -0.1567]], device='cuda:0')\n",
      "{'e': '-6.9017', 'ke': '3.6195', 'pe': '-10.5212', 'r': '0.0245', 'step': 451}\n",
      "tensor(2559.1481, device='cuda:0')\n",
      "tensor([[ 1.0087, -0.5165,  1.1854],\n",
      "        [ 1.0455,  0.9837, -0.2564]], device='cuda:0')\n",
      "{'e': '-6.7372', 'ke': '3.8709', 'pe': '-10.6081', 'r': '0.0301', 'step': 463}\n",
      "tensor(2403.8042, device='cuda:0')\n",
      "tensor([[-0.2075,  0.4649, -0.4357],\n",
      "        [-1.2903, -0.3372,  0.5970]], device='cuda:0')\n",
      "{'e': '-6.9793', 'ke': '3.7950', 'pe': '-10.7743', 'r': '0.0151', 'step': 476}\n"
     ]
    }
   ],
   "source": [
    "### train step ###\n",
    "from hwat_func import compute_ke_b, compute_pe_b\n",
    "from functorch import vmap, make_functional, grad\n",
    "import functorch\n",
    "\n",
    "# def train_step(model, model_v, _params, r_step):\n",
    "\n",
    "\t\n",
    "\n",
    "# \tv_tr = dict(\n",
    "# \t\tparams=params, \n",
    "#   \t\tgrads=grads,\n",
    "# \t\te=e, pe=pe, ke=ke,\n",
    "# \t\tr=r_step\n",
    "# \t)\n",
    "# \treturn v_tr\n",
    "\n",
    "\n",
    "r = r.to(device)\n",
    "center_points = center_points.to(device)\n",
    "\n",
    "# v_tr = train_step(model, params, r)\n",
    "# pprint.pprint({k:v.shape if isinstance(v, torch.Tensor) else len(v) for k,v in v_tr.items()})\n",
    "\n",
    "### init variables ###\n",
    "deltar = torch.tensor([0.02]).to(device)\n",
    "\n",
    "print(f\"\"\"exp/actual | \n",
    "\tcps    : {(c.data.n_e,3)}/{center_points.shape}\n",
    "\tr      : {(c.n_device, c.data.n_b, c.data.n_e, 3)}/{r.shape}\n",
    "\tdeltar : {(1,)}/{deltar.shape}\n",
    "\"\"\")\n",
    "\n",
    "### init functions ### \n",
    "from hwat_func import sample_b\n",
    "\n",
    "### train ###\n",
    "import wandb\n",
    "from hwat_func import keep_around_points\n",
    "from utils import compute_metrix\n",
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "### add in optimiser\n",
    "model = c.partial(Ansatz_fb).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "c.log_metric_step = 10\n",
    "### fix sampler\n",
    "### fix train step \n",
    "### metrix conversion\n",
    "model_fn, params = make_functional(model)\n",
    "model_v = vmap(model_fn, in_dims=(None, 0))\n",
    "\n",
    "# print(c.wandb_c.)\n",
    "wandb.define_metric(\"*\", step_metric=\"tr/step\")\n",
    "print('Go see:', c._run.url)\n",
    "v_tr = None\n",
    "for step in range(1, c.n_step+1):\n",
    "\tr_keep = r.clone()\n",
    "\twith torch.no_grad():\n",
    "     \n",
    "     \n",
    "\t\tmodel_fn, params = make_functional(model)\n",
    "\t\tmodel_v = vmap(model_fn, in_dims=(None, 0))\n",
    "\t\tmodel_rv = lambda _r: model_v(params, _r).sum()\n",
    "\n",
    "\t\tr, acc, deltar = sample_b(model_v, params, r, deltar, n_corr=c.data.n_corr)  # ‚ùóneeds testing  ‚úÖ\n",
    "\t\tr = keep_around_points(r, center_points, l=2.) if step < 200 else r\n",
    "\n",
    "\t\t# with torch.no_grad():\n",
    "\t\tke = compute_ke_b(model_rv, r)\n",
    "\t\tpe = compute_pe_b(r, c.data.a, c.data.a_z)\n",
    "\t\t# print(pe.shape, ke.shape)\n",
    "\t\te = pe + ke\n",
    "\t\te_mean_dist = torch.mean(torch.absolute(torch.median(e) - e))\n",
    "\t\t# print(e.shape, e_mean_dist.shape)\n",
    "\t\te_clip = torch.clip(e, min=e-5*e_mean_dist, max=e+5*e_mean_dist)\n",
    "\n",
    "\tmodel.zero_grad()\n",
    "\topt.zero_grad()\n",
    "\tloss = ((e_clip - e_clip.mean())*model_rv(r)).mean()\n",
    "\tloss.backward()\n",
    " \n",
    "\topt.step()\n",
    "\n",
    "\tv_tr = dict(\n",
    "\t\te=e, \n",
    "\t\tpe=pe,\n",
    "\t\tke=ke,\n",
    "\t\tr=r,\n",
    "\t\tparams=params,\n",
    "\t)\n",
    "\n",
    "\tif not (step % c.log_metric_step):\n",
    "\t\tmetrix = compute_metrix(v_tr)  # ‚ùó needs converting to torch, ie tree maps ‚úÖ\n",
    "\t\twandb.log({'tr/step':step, **metrix})\n",
    "\t\n",
    "\tdiff = time()-t0\n",
    "\tif diff > 10: \n",
    "\t\tt0 = time()\n",
    "\t\tprint(torch.absolute(r - r_keep).sum())\n",
    "\t\tprint(r[0][:2])\n",
    "\t\tpprint.pprint({k:f'{v.mean().item():.4f}' for k,v in v_tr.items() if isinstance(v, torch.Tensor)} | {'step': step})\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ```{toggle} env vars and jax debug config notes\n",
    "# ‚ùáÔ∏è Magic & debug not currently used\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %env CUDA_VISIBLE_DEVICES='3'\n",
    "# %env \"WANDB_NOTEBOOK_NAME\" \"run.ipynb\" # ‚ùïsame as notebook\n",
    "\n",
    "# from jax.config import config\n",
    "# config.update('jax_disable_jit', True)\n",
    "# ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b38d4d910256a52431c1e658e4ec4972e8b118bd5f76052a504536bbce1f208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
