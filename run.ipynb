{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from jax.config import config\n",
    "config.update('jax_disable_jit', True)\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "import wandb\n",
    "\n",
    "from jax import vmap\n",
    "from functools import partial\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random as rnd\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.training import common_utils\n",
    "from flax import linen as nn, jax_utils\n",
    "import optax\n",
    "\n",
    "from pyfig import Pyfig\n",
    "import os\n",
    "from utils import debug, wpr\n",
    "from typing import Callable\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 20:15:28.777897: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:497] The NVIDIA driver's CUDA version is 11.4 which is older than the ptxas CUDA version (11.6.55). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'TMP': PosixPath('/home/amawi/projects/hwat/exp/tmp'),\n",
      " 'commit_id': '76377b6',\n",
      " 'data': {'a': DeviceArray([[0., 0., 0.]], dtype=float32),\n",
      "          'a_z': DeviceArray([4.], dtype=float32),\n",
      "          'n_b': 16,\n",
      "          'n_d': 2,\n",
      "          'n_e': 4,\n",
      "          'n_u': 2},\n",
      " 'data_dir': PosixPath('/home/amawi/projects/data'),\n",
      " 'dtype': 'f32',\n",
      " 'entity': 'xmax1',\n",
      " 'env': 'dex',\n",
      " 'exp_id': 'qpSsCK4',\n",
      " 'exp_name': 'junk',\n",
      " 'exp_path': PosixPath('/home/amawi/projects/hwat/exp/junk/qpSsCK4'),\n",
      " 'git_branch': 'main',\n",
      " 'git_remote': 'origin',\n",
      " 'half_precision': True,\n",
      " 'iter_exp_dir': True,\n",
      " 'log_metric_step': 5,\n",
      " 'log_sample_step': 5,\n",
      " 'log_state_step': 10,\n",
      " 'merge': <bound method Pyfig.merge of <pyfig.Pyfig object at 0x7fa704c3b460>>,\n",
      " 'model': {'compute_p_emb': functools.partial(<function compute_emb at 0x7fa63b393e20>, terms=['xx']),\n",
      "           'compute_s_emb': functools.partial(<function compute_emb at 0x7fa63b393e20>, terms=['x_rlen']),\n",
      "           'compute_s_perm': functools.partial(<function compute_s_perm at 0x7fa639f37880>, n_u=2),\n",
      "           'n_det': 1,\n",
      "           'n_fb': 2,\n",
      "           'n_fb_out': 64,\n",
      "           'n_pv': 8,\n",
      "           'n_sv': 16,\n",
      "           'terms_p_emb': ['xx'],\n",
      "           'terms_s_emb': ['x_rlen']},\n",
      " 'n_device': 1,\n",
      " 'n_epoch': 20,\n",
      " 'n_step': 1000,\n",
      " 'opt': {'beta1': 0.9,\n",
      "         'beta2': 0.99,\n",
      "         'eps': 1e-08,\n",
      "         'loss': 'l1',\n",
      "         'lr': 0.001,\n",
      "         'optimizer': 'Adam'},\n",
      " 'project': 'hwat',\n",
      " 'project_cfg_dir': PosixPath('/home/amawi/projects/hwat/cfg'),\n",
      " 'project_exp_dir': PosixPath('/home/amawi/projects/hwat/exp'),\n",
      " 'project_path': PosixPath('/home/amawi/projects/hwat'),\n",
      " 'project_root': PosixPath('/home/amawi/projects'),\n",
      " 'run_path': PosixPath('/home/amawi/projects/hwat/run.py'),\n",
      " 'seed': 808017424,\n",
      " 'server': 'svol.fysik.dtu.dk',\n",
      " 'server_project_path': PosixPath('/home/amawi/projects/hwat'),\n",
      " 'slurm': {'cpus_per_task': 1,\n",
      "           'error': PosixPath('/home/amawi/projects/hwat/exp/tmp/e-%j.err'),\n",
      "           'gres': 'gpu:RTX3090:1',\n",
      "           'job_name': 'junk',\n",
      "           'mail_type': 'FAIL',\n",
      "           'nodes': 1,\n",
      "           'ntasks': 8,\n",
      "           'output': PosixPath('/home/amawi/projects/hwat/exp/tmp/o-%j.out'),\n",
      "           'partition': 'sm3090',\n",
      "           'sbatch': ' \\n'\n",
      "                     '            module purge \\n'\n",
      "                     '            source ~/.bashrc \\n'\n",
      "                     '            module load GCC \\n'\n",
      "                     '            module load CUDA/11.4.1 \\n'\n",
      "                     '            module load cuDNN/8.2.2.26-CUDA-11.4.1 \\n'\n",
      "                     '            conda activate dex \\n'\n",
      "                     '            export MKL_NUM_THREADS=1 \\n'\n",
      "                     '            export NUMEXPR_NUM_THREADS=1 \\n'\n",
      "                     '            export OMP_NUM_THREADS=1 \\n'\n",
      "                     '            export OPENBLAS_NUM_THREADS=1\\n'\n",
      "                     '            pwd\\n'\n",
      "                     '            nvidia-smi\\n'\n",
      "                     \"            mv_cmd = f'mv \"\n",
      "                     '/home/amawi/projects/hwat/exp/tmp/o-$SLURM_JOB_ID.out '\n",
      "                     '/home/amawi/projects/hwat/exp/tmp/e-$SLURM_JOB_ID.err '\n",
      "                     \"$out_dir' \\n\"\n",
      "                     '    ',\n",
      "           'time': '0-12:00:00'},\n",
      " 'submit_state': -1,\n",
      " 'sweep': {'method': 'random',\n",
      "           'metrics': {'goal': 'minimize', 'name': 'validation_loss'},\n",
      "           'n_sweep': 10,\n",
      "           'name': 'sweep',\n",
      "           'parameters': {'batch_size': {'values': [16, 32, 64]},\n",
      "                          'epoch': {'values': [5, 10, 15]},\n",
      "                          'lr': {'max': 0.1, 'min': 0.0001}},\n",
      "           'run_cap': 10,\n",
      "           'sweep_id': ''},\n",
      " 'user': 'amawi',\n",
      " 'wandb': {'entity': 'xmax1', 'job_type': 'training'}}\n"
     ]
    }
   ],
   "source": [
    "c = Pyfig(wandb_mode='disabled', debug=True)  # online:on|disabled:off|offline:local, True:\n",
    "pprint(c.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-6.689785, dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hwat import FermiNet, init_walker\n",
    "\n",
    "rng = rnd.PRNGKey(c.seed)\n",
    "\n",
    "x_init = rnd.normal(rng, (c.data.n_e, 3)) # NB no batch dim - batchless implementation\n",
    "\n",
    "model = c.partial(FermiNet)\n",
    "params = model.init(rng, x_init)['params'] # {'params':p, ... other variables if they exist}\n",
    "model.apply({'params':params}, x_init) # potentially the only way to run something in jax\n",
    "# model(x_init) # Can't call compact methods on unbound modules - what? - Unbound meaning not associated w another module\n",
    "# see state.apply_fn(params, x_init) below for more craziness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.pmap, axis_name='b')\n",
    "def create_train_state(rng):\n",
    "\tmodel = c.partial(FermiNet)\n",
    "\tx = rnd.normal(rng, (c.data.n_e, 3))\n",
    "\tparams = model.init(rng, x)['params']\n",
    "\ttx = optax.sgd(c.opt.lr)\n",
    "\treturn TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "rng_n = rnd.split(rng, len(jax.devices()))\n",
    "state = create_train_state(rng_n)\n",
    "state = jax_utils.replicate(state)\n",
    "# state.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# wpr(dict(p=state.params))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m debug(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mtype\u001b[39m(state\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/.conda/envs/dex/lib/python3.10/site-packages/flax/core/frozen_dict.py:66\u001b[0m, in \u001b[0;36mFrozenDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m---> 66\u001b[0m   v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict[key]\n\u001b[1;32m     67\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, \u001b[39mdict\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m FrozenDict(v)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'params'"
     ]
    }
   ],
   "source": [
    "# debug(True)\n",
    "# wpr(dict(p=state.params))\n",
    "# debug(False)\n",
    "# type(state.params) # is the param dictionary, not the variable dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walker shape:  (16, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "from hwat import SampleState\n",
    "x = init_walker(rng, c.data.n_b, c.data.n_u, c.data.n_d, center=c.data.a, std=0.1)\n",
    "print('Walker shape: ', x.shape)\n",
    "model.apply({'params':params}, x_init) # potentially the only way to run something in jax\n",
    "sample = SampleState(rng, model=model)\n",
    "sample_vmap = vmap(sample, in_axes=(None, 0))\n",
    "# sample_vmap(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walker shape:  (16, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([  22.007858, -141.53467 ,  -45.23154 ,  -95.129295,\n",
       "             -116.35297 , -173.2504  ,  -62.280594,  -60.103165,\n",
       "              -98.63029 ,  -84.12774 ,  -81.23646 , -110.813065,\n",
       "             -161.86557 ,  -86.836624, -127.94581 ,  -89.53885 ],            dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hwat import compute_pe\n",
    "print('Walker shape: ', x.shape)\n",
    "compute_pe(x, c.data.a, c.data.a_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 3115.9775  ,   -77.107544,    24.304708,   -15.595001,\n",
       "                36.848007,    31.614841,    14.340487,   -34.231533,\n",
       "               240.05957 ,  -137.8808  ,   813.81354 ,    64.84529 ,\n",
       "             -4007.5537  ,  -185.4494  ,    68.41682 ,   -21.068924],            dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hwat import create_compute_ke\n",
    "debug(False)\n",
    "compute_ke = create_compute_ke(model)\n",
    "compute_ke(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train step framework get\n",
    "# train step framework copy\n",
    "# test energy function\n",
    "# kinetic energy\n",
    "# potential energy\n",
    "# include atoms\n",
    "# include sampler\n",
    "# write metric\n",
    "# run loop\n",
    "\n",
    "@partial(jax.pmap, axis_name='x')\n",
    "def train_step(state, x):\n",
    "\tparams = state.params\n",
    "\n",
    "\tx = sample(params, x)\n",
    "\n",
    "\tke = c.compute_ke()\n",
    "\tpe = c.compute_pe()\n",
    "\te = ke+pe\n",
    "\n",
    "\tdef loss_fn(p):\n",
    "\t\tout = state.apply({'params': p}, x) \n",
    "\t\treturn jnp.mean(out*e)\n",
    "\n",
    "\tgrad_fn = jax.value_and_grad(loss_fn, has_aux=False)  # has_aux for more than one out\n",
    "\tout, grads = grad_fn(params)\n",
    "\tlog_psi = out\t\t\n",
    "\t\t\n",
    "\tv_b = dict( # scalars\n",
    "\t\t\t: pe,\n",
    "\t\t\t: ke,\n",
    "\t\t\t: e,\n",
    "\t\t\t: log_psi,\n",
    "\t\t\t: sample.move_std,\n",
    "\t\t\t: x\n",
    "\t)\n",
    "\n",
    "\treturn state, grads, x, v_b\n",
    "\n",
    "@jax.pmap\n",
    "def update_model(state, grads):\n",
    "\treturn state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.define_metric(\"*\", step_metric=\"train/step\")\n",
    "\n",
    "def compute_metric(d:dict):\n",
    "    ...\n",
    "    metrics = lax.pmean(metrics, axis_name='b')\n",
    "\n",
    "    return metric\n",
    "c = Pyfig(wandb_mode='disabled', debug=True)  # online:on|disabled:off|offline:local, True:\n",
    "# pprint(c.d)\n",
    "\n",
    "# # Display a project workspace\n",
    "# %wandb USERNAME/PROJECT\n",
    "# # Display a single run\n",
    "# %wandb USERNAME/PROJECT/runs/RUN_ID\n",
    "# # Display a sweep\n",
    "# %wandb USERNAME/PROJECT/sweeps/SWEEP_ID\n",
    "# # Display a report\n",
    "# %wandb USERNAME/PROJECT/reports/REPORT_ID\n",
    "# # Specify the height of embedded iframe\n",
    "# %wandb USERNAME/PROJECT -h 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = []\n",
    "\n",
    "for step in range(c.n_step):\n",
    "        \n",
    "    state, grads, x, data = train_step(state, x)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    if step % c.log_metric_step == 0:\n",
    "        \n",
    "        # r'sgn$(\\cdot)$'     : sgn\n",
    "        metric = compute_metric(metric)\n",
    "        \n",
    "        summary = {\n",
    "            f'train/{k}': v\n",
    "            for k, v in jax.tree_map(lambda x: x.mean(), train_metrics).items()\n",
    "        }\n",
    "\n",
    "        wandb.log({\n",
    "                \"train/step\": step, \n",
    "                **summary\n",
    "        })\n",
    "\n",
    "nice_keys = dict(\n",
    "    r'V(X)'    \t\t\t\t\n",
    "    r'$\\nabla^2'    \t\t\n",
    "    'E'\t\t\t\t\t\t\n",
    "    r'$\\log\\psi$' \t\t\t\n",
    "    r'\\delta_\\mathrm{r}'\t\n",
    "    r'r_\\mathrm{e}'\t\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA Decay extension\n",
    "if step <= c.ema.update_after_step:\n",
    "            state = p_copy_params_to_ema(state)\n",
    "\n",
    "        elif step % c.ema.update_every == 0:\n",
    "            ema_decay = ema_decay_fn(step)\n",
    "            state =  p_apply_ema(state, ema_decay)\n",
    "\n",
    "def create_model_apply():\n",
    "        model = c.pass_arg(FermiNet)\n",
    "        model.init(rng, rnd.normal(rng, (c.data.n_e, 3)))\n",
    "        @vmap\n",
    "        def model_apply(x):\n",
    "            out = model.apply(params, x)\n",
    "            return out.sum()\n",
    "        return model_apply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
