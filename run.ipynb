{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path exists, leaving alone\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from jax.config import config\n",
    "config.update('jax_disable_jit', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from functools import partial, reduce\n",
    "import wandb\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random as rnd\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.training import common_utils\n",
    "from flax import linen as nn, jax_utils\n",
    "import optax\n",
    "\n",
    "from pyfig import Pyfig\n",
    "from hwat import create_masks, logabssumdet\n",
    "\n",
    "c = Pyfig(wandb_mode='disabled', notebook=True) # online:on|disabled:off|offline:local, True: \n",
    "c.print()\n",
    "\n",
    "class FermiNet(nn.Module):\n",
    "  \n",
    "  n_sv: int\n",
    "  n_pv: int\n",
    "  n_fb: int\n",
    "  n_fb_out: int\n",
    "  n_det: int\n",
    "\n",
    "  af_fb: Callable\n",
    "  af_fb_out: Callable\n",
    "  af_pseudo: Callable\n",
    "\n",
    "  compute_s_emb: Callable\n",
    "  compute_p_emb: Callable\n",
    "  \n",
    "  n_e: int\n",
    "  n_u: int\n",
    "  n_d: int = n_e-n_u\n",
    "  p_mask_u, p_mask_d = create_masks(n_e, n_u)\n",
    "  compute_s_perm: Callable = partial(compute_s_perm, p_mask_u=p_mask_u, p_mask_d=p_mask_d, n_u=n_u)\n",
    "\n",
    "  pbc:          bool = False\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(_i, x):\n",
    "    \n",
    "    n_e, n_u, n_d, n_det = _i.n_e, _i.n_u, _i.n_d, _i.n_det\n",
    "\n",
    "    x_s_var = _i.compute_s_emb(x)\n",
    "    x_p_var = _i.compute_p_emb(x)\n",
    "\n",
    "    x_s_res = x_p_res = 0.\n",
    "    for _ in range(_i.n_fb):\n",
    "        x_p_var = x_p_res = _i.af_fb(nn.Dense(_i.n_pv)(x_p_var)) + x_p_res\n",
    "        \n",
    "        x_s_var = _i.compute_s_perm(x_s_var, x_p_var)\n",
    "        x_s_var = x_s_res = _i.af_fb(nn.Dense(_i.n_sv)(x_s_var)) + x_s_res\n",
    "\n",
    "    x_w = jnp.concatentate([x_s_var, x_p_var], axis=-1)\n",
    "    x_w = _i.af_fb_out(nn.Dense(_i.n_fb_out)(x_w))\n",
    "    x_w = _i.af_pseudo(nn.Dense(n_det*n_e)(x_w))\n",
    "    x_wu, x_wd = jnp.split(x_w, [n_u, n_d], axis=0)\n",
    "    \n",
    "    orb_u = jnp.split(x_wu * jnp.exp(-nn.Dense(n_u*n_det)), n_det, axis=1)\n",
    "    orb_d = jnp.split(x_wd * jnp.exp(-nn.Dense(n_d*n_det)), n_det, axis=1)\n",
    "\n",
    "    log_psi, sgn = logabssumdet(orb_u, orb_d)\n",
    "\n",
    "    return log_psi\n",
    "\n",
    "model = FermiNet(**c.dict)\n",
    "n_e = 10\n",
    "rng_model = rnd.PRNGKey(1)\n",
    "x = jnp.ones(n_e, 3)\n",
    "params = model.init(rng_model, x)\n",
    "model.apply(params, x)\n",
    "\n",
    "\n",
    "# p_sample_step = jax.pmap(sample_step, axis_name='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# jax.tree_map(lambda x: x.shape, params) # Check the parameters\n",
    "\n",
    "def create_train_state(c: Pyfig):\n",
    "  model = CNN()\n",
    "  params = model.init(c.rng_init, jnp.ones([1, 28, 28, 1]))['params']\n",
    "  tx = optax.sgd(c.lr)\n",
    "  return TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "state = create_train_state(c)\n",
    "state = jax_utils.replicate(state)\n",
    "\n",
    "@jax.jit\n",
    "def train_step(params, state, b):\n",
    "  \n",
    "  b_energy = compute_energy(state)\n",
    "  \n",
    "  def loss_fn(p):\n",
    "    model_out = state.apply_fn({'params':p}, b)\n",
    "    log_psi, sgn = model_out\n",
    "    return log_psi, sgn\n",
    "  \n",
    "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "  (log_psi, sgn), grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  \n",
    "  variables = {\n",
    "    'E batch'           : b_energy,\n",
    "    r'$\\log\\psi$ batch' : log_psi,\n",
    "    r'sgn$(\\cdot)$'     : sgn\n",
    "  }\n",
    "  \n",
    "  metrics = compute_metric(b_energy, log_psi, sgn)\n",
    "  return state, metrics\n",
    "\n",
    "train_step = jax.pmap(train_step, axis_name='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_params_to_ema(state):\n",
    "   state = state.replace(params_ema = state.params)\n",
    "   return state\n",
    "\n",
    "def apply_ema_decay(state, ema_decay):\n",
    "    params_ema = jax.tree_map(lambda p_ema, p: p_ema * ema_decay + p * (1. - ema_decay), state.params_ema, state.params)\n",
    "    state = state.replace(params_ema = params_ema)\n",
    "    return state\n",
    "\n",
    "p_apply_ema = jax.pmap(apply_ema_decay, in_axes=(0, None), axis_name='batch')\n",
    "p_copy_params_to_ema = jax.pmap(copy_params_to_ema, axis_name='batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "def to_wandb_config(d, parent_key: str = '', sep: str ='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(to_wandb_config(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            if isinstance(v, Path):\n",
    "                v = str(v)\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "wandb.init(\n",
    "    job_type=c.wandb.job_type,\n",
    "    entity=c.wandb.entity,\n",
    "    project=c.project,\n",
    "    config=to_wandb_config(c.dict),\n",
    "    settings=wandb.Settings(start_method='fork'),  # idk why this is an issue\n",
    "    dir=c.exp_path,\n",
    ")\n",
    "\n",
    "wandb.define_metric(\"*\", step_metric=\"train/step\")\n",
    "\n",
    "# # Display a project workspace\n",
    "# %wandb USERNAME/PROJECT\n",
    "# # Display a single run\n",
    "# %wandb USERNAME/PROJECT/runs/RUN_ID\n",
    "# # Display a sweep\n",
    "# %wandb USERNAME/PROJECT/sweeps/SWEEP_ID\n",
    "# # Display a report\n",
    "# %wandb USERNAME/PROJECT/reports/REPORT_ID\n",
    "# # Specify the height of embedded iframe\n",
    "# %wandb USERNAME/PROJECT -h 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_stats():\n",
    "    def normalize_to_neg_one_to_one(img):\n",
    "        return img * 2 - 1  \n",
    "    data_tr = datasets.FashionMNIST(\n",
    "        root=c.data_dir, \n",
    "        download=True, \n",
    "        train=True,\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(28),\n",
    "            transforms.CenterCrop(28),\n",
    "        ]),\n",
    "        target_transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "    ])\n",
    "    )\n",
    "    imgs = torch.stack([img_t for img_t, _ in data_tr], dim=3)\n",
    "    mean = imgs.view(1,-1).mean(dim=1) \n",
    "    std = imgs.view(1,-1).std(dim=1)\n",
    "    print('Data mean: ', mean, 'Data std: ', std)\n",
    "    return mean, std\n",
    "mean, std = get_data_stats()\n",
    "loader_tr, loader_test = get_fashion_loader(c.data.b_size, c.data_dir, mean=mean, std=std)  # is not an iterator or list\n",
    "img, l = next(iter(loader_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Image.fromarray(np.uint8((img[0, 0]*std+mean).cpu().numpy()*255))\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('1', size=(cols*w, rows*h))\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "\n",
    "    return grid\n",
    "std = float(std.cpu().numpy())\n",
    "mean = float(mean.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = []\n",
    "\n",
    "for ep in range(c.n_epoch):\n",
    "    for step, (b, target) in enumerate(loader_tr):\n",
    "        b = jnp.squeeze(jnp.expand_dims(jnp.array(b.numpy()), axis=(0,-1)), axis=2) # p, B, H, W, C\n",
    "        rng, *train_step_rng = jax.random.split(rng, num=jax.local_device_count() + 1)\n",
    "        train_step_rng = jnp.array(train_step_rng)\n",
    "        \n",
    "        state, metrics = p_train_step(train_step_rng, state, b)\n",
    "\n",
    "        if step <= c.ema.update_after_step:\n",
    "            state = p_copy_params_to_ema(state)\n",
    "\n",
    "        elif step % c.ema.update_every == 0:\n",
    "            ema_decay = ema_decay_fn(step)\n",
    "            state =  p_apply_ema(state, ema_decay)\n",
    "\n",
    "        if step % c.log_metric_step == 0:\n",
    "\n",
    "            train_metrics.append(metrics)\n",
    "            train_metrics = common_utils.get_metrics(train_metrics)\n",
    "            \n",
    "            summary = {\n",
    "                f'train/{k}': v\n",
    "                for k, v in jax.tree_map(lambda x: x.mean(), train_metrics).items()\n",
    "            }\n",
    "\n",
    "            train_metrics = []\n",
    "            b = ((np.array(b)*std+mean)*255).astype(np.uint8)\n",
    "            imgs = [wandb.Image(Image.fromarray(b[0, i].reshape(28, 28))) for i in range(9)]\n",
    "            \n",
    "            wandb.log({\n",
    "                    \"train/step\": step, \n",
    "                    'train/sample': imgs,\n",
    "                    **summary\n",
    "            })\n",
    " \n",
    "    print('Epoch: ', ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.fromarray(b[0, 0].reshape(28, 28, 1))\n",
    "b[0, 0].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
