{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmerged a_z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxmax1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./dump/wandb/run-20221209_133825-2wbk7jpx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xmax1/hwat/runs/2wbk7jpx\" target=\"_blank\">gentle-cosmos-294</a></strong> to <a href=\"https://wandb.ai/xmax1/hwat\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:  xmax1/hwat/2wbk7jpx ‚úÖ\n",
      "ü§ñ 1 GPUs available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' copy lines and run in analysis while the exp is live '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Distribution ‚ú® ‚ùá Demo üí™ ### \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "### fancy logging variables, philosophically reminding us of the goal ###\n",
    "fancy = dict(\n",
    "\t\tpe\t\t= r'$V(X)',    \t\t\t\t\n",
    "\t\tke\t\t= r'$\\nabla^2',    \t\t\n",
    "\t\te\t\t= r'$E',\t\t\t\t\t\t\n",
    "\t\tlog_psi\t= r'$\\log\\psi', \t\t\t\n",
    "\t\tdeltar\t= r'$\\delta_\\mathrm{r}',\t\n",
    "\t\tx\t\t= r'$r_\\mathrm{e}',\n",
    ")\n",
    "\n",
    "### pyfig ###\n",
    "from pyfig import Pyfig\n",
    "\n",
    "args = {\n",
    "\t'l_e':[4,], \n",
    "\t'a_z':[4,], \n",
    "\t'n_u': 2,\n",
    "\t'n_b': 512, \n",
    "\t'n_sv': 32, \n",
    "\t'n_pv': 32, \n",
    "\t'n_corr': 20, \n",
    "\t'n_step': 10000, \n",
    "\t'log_metric_step': 50, \n",
    "\t'exp_name':'junk',\n",
    "\t'sweep': {'n_b': {'values': [1, 2, 10]}}\n",
    "}\n",
    "\n",
    "\n",
    "c = Pyfig(wandb_mode='online', args=args, get_sys_arg=False, submit=True, sweep=True)\n",
    "\n",
    "n_device = c.n_device\n",
    "print(f'ü§ñ {n_device} GPUs available')\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(c.d)\n",
    "\n",
    "\"\"\" live plotting in another notebook \"\"\"\n",
    "\"\"\" copy lines and run in analysis while the exp is live \"\"\"\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<run-here>\")\n",
    "# c = run.config\n",
    "# h = run.history()\n",
    "# s = run.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 3dbaa50] \"run_things\"\n",
      " Committer: Adam Maximilian Wilson <amawi@oceanus.imm.dtu.dk>\n",
      "Your name and email address were configured automatically based\n",
      "on your username and hostname. Please check that they are accurate.\n",
      "You can suppress this message by setting them explicitly. Run the\n",
      "following command and follow the instructions in your editor to edit\n",
      "your configuration file:\n",
      "\n",
      "    git config --global --edit\n",
      "\n",
      "After doing this, you may fix the identity used for this commit with:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 4 files changed, 51 insertions(+), 8 deletions(-)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['git', 'commit', '-a', '-m', '\"run_things\"'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import run\n",
    "\n",
    "# run(['git', 'commit', '-m', '\"run_things\"'])\n",
    "run(['git', 'commit', '-a', '-m', '\"run_things\"'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp/actual | \n",
      "\trng    : (2,)/(2,) \n",
      "\trng_p  : (1, 2)/(1, 2) \n",
      "\tcps    : (4, 3)/(4, 3)\n",
      "\tr      : (1, 512, 4, 3)/(1, 512, 4, 3)\n",
      "\tdeltar : (1, 1)/(1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### model (aka TrainState) ### \n",
    "from functools import partial\n",
    "import jax\n",
    "import optax\n",
    "from flax.training.train_state import TrainState\n",
    "from hwat import FermiNet\n",
    "\n",
    "@partial(jax.pmap, axis_name='dev', in_axes=(0,0))\n",
    "def create_train_state(rng, r):\n",
    "\tmodel = c.partial(FermiNet)\n",
    "\tparams = model.init(rng, r)\n",
    "\topt = optax.chain(optax.clip_by_block_rms(1.),optax.adamw(0.001))\n",
    "\treturn TrainState.create(apply_fn=model.apply, params=params, tx=opt)\n",
    "\n",
    "### train step ###\n",
    "from jax import numpy as jnp\n",
    "from hwat import compute_ke_b, compute_pe_b\n",
    "from typing import NamedTuple\n",
    "\n",
    "@partial(jax.pmap, in_axes=(0, 0))\n",
    "def train_step(state, r_step):\n",
    "\n",
    "\tke = compute_ke_b(state, r_step)\n",
    "\tpe = compute_pe_b(r_step, c.data.a, c.data.a_z)\n",
    "\te = pe + ke\n",
    "\t\n",
    "\te_mean_dist = jnp.mean(jnp.abs(jnp.median(e) - e))\n",
    "\te_clip = jnp.clip(e, a_min=e-5*e_mean_dist, a_max=e+5*e_mean_dist)\n",
    "\n",
    "\tdef loss(params):\n",
    "\t\treturn ((e_clip - e_clip.mean())*state.apply_fn(params, r_step)).mean()\n",
    "\t\n",
    "\tgrads = jax.grad(loss)(state.params)\n",
    "\tstate = state.apply_gradients(grads=grads)\n",
    "\t\n",
    "\tv_tr = dict(\n",
    "\t\tparams=state.params, grads=grads,\n",
    "\t\te=e, pe=pe, ke=ke,\n",
    "\t\tr=r_step\n",
    "\t)\n",
    "\n",
    "\treturn state, v_tr\n",
    "\n",
    "\n",
    "### init variables ###\n",
    "from utils import gen_rng\n",
    "from hwat import init_r, get_center_points\n",
    "from jax import random as rnd\n",
    "\n",
    "rng, rng_p = gen_rng(rnd.PRNGKey(c.seed), c.n_device)\n",
    "center_points = get_center_points(c.data.n_e, c.data.a)\n",
    "r = init_r(rng_p, c.data.n_b, c.data.n_e, center_points, std=0.1)\n",
    "deltar = jnp.array([0.02])[None, :].repeat(n_device, axis=0)\n",
    "\n",
    "print(f\"\"\"exp/actual | \n",
    "\trng    : {(2,)}/{rng.shape} \n",
    "\trng_p  : {(c.n_device,2)}/{rng_p.shape} \n",
    "\tcps    : {(c.data.n_e,3)}/{center_points.shape}\n",
    "\tr      : {(c.n_device, c.data.n_b, c.data.n_e, 3)}/{r.shape}\n",
    "\tdeltar : {(c.n_device, 1)}/{deltar.shape}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "### init functions ### \n",
    "from hwat import sample_b\n",
    "\n",
    "state = create_train_state(rng_p, r)\n",
    "metro_hast = jax.pmap(partial(sample_b, n_corr=c.data.n_corr), in_axes=(0,0,0,0))\n",
    "\n",
    "\n",
    "### train ###\n",
    "import wandb\n",
    "from hwat import keep_around_points\n",
    "from utils import compute_metrix\n",
    "\n",
    "wandb.define_metric(\"*\", step_metric=\"tr/step\")\n",
    "for step in range(1, c.n_step+1):\n",
    "\trng, rng_p = gen_rng(rng, c.n_device)\n",
    "\n",
    "\tr, acc, deltar = metro_hast(rng_p, state, r, deltar)\n",
    "\tr = keep_around_points(r, center_points, l=2.) if step < 1000 else r\n",
    "\t\n",
    "\tstate, v_tr = train_step(state, r)\n",
    "\n",
    "\tif not (step % c.log_metric_step):\n",
    "\t\tmetrix = compute_metrix(v_tr)\n",
    "\t\twandb.log({'tr/step':step, **metrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ```{toggle} env vars and jax debug config notes\n",
    "# ‚ùáÔ∏è Magic & debug not currently used\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %env CUDA_VISIBLE_DEVICES='3'\n",
    "# %env \"WANDB_NOTEBOOK_NAME\" \"run.ipynb\" # ‚ùïsame as notebook\n",
    "\n",
    "# from jax.config import config\n",
    "# config.update('jax_disable_jit', True)\n",
    "# ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
