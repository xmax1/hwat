{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"hwat-notebook\"\n"
     ]
    }
   ],
   "source": [
    "# Distribution ✨ jit ❇ Demo 💪 \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"hwat-notebook\"\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "# from jax.config import config\n",
    "# config.update('jax_disable_jit', True)\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import re as regex\n",
    "from pprint import pprint\n",
    "\n",
    "import jax\n",
    "from jax import pmap, grad\n",
    "from jax import numpy as jnp\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.core.frozen_dict import FrozenDict\t\n",
    "\n",
    "from pyfig import Pyfig\n",
    "from hwat import FermiNet, sample, compute_ke_b, PotentialEnergy\n",
    "from hwat import PotentialEnergy, sample, compute_ke_b\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(k, v, new_d, p='tr', suf='', sep='/', sep_long='-'):\n",
    "\tdepth = p.count('/')\n",
    "\tif depth > 1:\n",
    "\t\tsep = sep_long\n",
    "\tif isinstance(v, dict):\n",
    "\t\tfor k_sub,v_sub in v.items():\n",
    "\t\t\tcollect_stats(k, v_sub, new_d, p=(p+sep+k_sub))\n",
    "\telse:\n",
    "\t\tnew_d[p+sep+k+suf] = v\n",
    "\treturn new_d\n",
    "\n",
    "def compute_metrix(d:dict, mode='tr'):\n",
    "\tpattern_ignore = [\n",
    "\t\t'.*Dense_[1-9].*'\n",
    "\t\t'.*rng_.*',\n",
    "\t]\n",
    "\tfancy = dict(\n",
    "\t\tpe\t\t= r'$V(X)',    \t\t\t\t\n",
    "\t\tke\t\t= r'$\\nabla^2',    \t\t\n",
    "\t\te\t\t= r'$E',\t\t\t\t\t\t\n",
    "\t\tlog_psi\t= r'$\\log\\psi', \t\t\t\n",
    "\t\tdeltar\t= r'$\\delta_\\mathrm{r}',\t\n",
    "\t\tx\t\t= r'$r_\\mathrm{e}',\n",
    "\t)\n",
    "\t_d = {}\n",
    "\tfor k,v in d.items():\n",
    "\t\tk = fancy.get(k, k)\n",
    "\t\tif isinstance(v, FrozenDict):\n",
    "\t\t\tv = v.unfreeze()\n",
    "\n",
    "\t\tv = jax.tree_map(lambda x: np.array(jax.device_get(x)), v)\n",
    "\t\tv_mean = jax.tree_map(lambda x: x.mean() if not np.isscalar(x) else x, v)\n",
    "\t\tv_std = jax.tree_map(lambda x: x.std(), v)\n",
    "\n",
    "\t\t_d = collect_stats(k, v_mean, _d, p=mode, suf=r'_\\mu$')\n",
    "\t\t_d = collect_stats(k, v_std, _d, p=mode, suf=r'_\\sigma$')\n",
    "\n",
    "\t# return {k:v for k,v in _d.items() if not any([regex.match(k, pat) for pat in pattern_ignore])}\n",
    "\treturn {k:v for k,v in _d.items() if not any([pat in k for pat in pattern_ignore])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_root': PosixPath('/home/amawi/projects'),\n",
       " 'project': 'hwat',\n",
       " 'data_dir': PosixPath('/home/amawi/projects/data'),\n",
       " 'run_path': PosixPath('/home/amawi/projects/hwat/run.py'),\n",
       " 'exp_name': 'demo',\n",
       " 'exp_id': '2SbUE9h',\n",
       " 'dtype': 'f32',\n",
       " 'n_step': 20,\n",
       " 'log_metric_step': 5,\n",
       " 'log_sample_step': 5,\n",
       " 'log_state_step': 10,\n",
       " 'seed': 808017424,\n",
       " 'rng_init': DeviceArray([[3855292491, 2129030713],\n",
       "              [ 880713437, 1121735675]], dtype=uint32),\n",
       " 'data': {'n_b': 16,\n",
       "  'n_e': 6,\n",
       "  'n_u': 3,\n",
       "  'n_d': 3,\n",
       "  'a': DeviceArray([[0., 0., 0.]], dtype=float32),\n",
       "  'a_z': DeviceArray([6.], dtype=float32),\n",
       "  'init_walker': functools.partial(<function init_walker at 0x7f6975c549d0>, n_b=16, n_u=3, n_d=3, center=DeviceArray([[0., 0., 0.]], dtype=float32), std=0.1),\n",
       "  'corr_len': 20,\n",
       "  'acc_target': 0.5},\n",
       " 'model': {'n_sv': 32,\n",
       "  'n_pv': 16,\n",
       "  'n_fb': 16,\n",
       "  'n_det': 1,\n",
       "  'n_fb_out': 128,\n",
       "  'terms_s_emb': ['x_rlen'],\n",
       "  'terms_p_emb': ['xx'],\n",
       "  'compute_s_emb': functools.partial(<function compute_emb at 0x7f6975c2b370>, terms=['x_rlen']),\n",
       "  'compute_p_emb': functools.partial(<function compute_emb at 0x7f6975c2b370>, terms=['xx']),\n",
       "  'compute_s_perm': functools.partial(<function compute_s_perm at 0x7f6975c54160>, n_u=3)},\n",
       " 'opt': {'optimizer': 'Adam',\n",
       "  'b1': 0.9,\n",
       "  'b2': 0.99,\n",
       "  'eps': 1e-08,\n",
       "  'lr': 0.0001,\n",
       "  'loss': 'l1',\n",
       "  'tx': GradientTransformation(init=<function chain.<locals>.init_fn at 0x7f66f434b010>, update=<function chain.<locals>.update_fn at 0x7f66f434b490>)},\n",
       " 'sweep': {'method': 'random',\n",
       "  'name': 'sweep',\n",
       "  'metrics': {'goal': 'minimize', 'name': 'validation_loss'},\n",
       "  'parameters': {'batch_size': {'values': [16, 32, 64]},\n",
       "   'epoch': {'values': [5, 10, 15]},\n",
       "   'lr': {'max': 0.1, 'min': 0.0001}},\n",
       "  'n_sweep': 10,\n",
       "  'sweep_id': ''},\n",
       " 'wandb_c': {'job_type': 'training', 'entity': 'xmax1', 'wandb_run_path': },\n",
       " 'slurm': {'mail_type': 'FAIL',\n",
       "  'partition': 'sm3090',\n",
       "  'nodes': 1,\n",
       "  'ntasks': 8,\n",
       "  'cpus_per_task': 1,\n",
       "  'time': '0-12:00:00',\n",
       "  'gres': 'gpu:RTX3090:1',\n",
       "  'output': PosixPath('/home/amawi/projects/hwat/exp/tmp/o-%j.out'),\n",
       "  'error': PosixPath('/home/amawi/projects/hwat/exp/tmp/e-%j.err'),\n",
       "  'job_name': 'demo',\n",
       "  'sbatch': \" \\n            module purge \\n            source ~/.bashrc \\n            module load GCC \\n            module load CUDA/11.4.1 \\n            module load cuDNN/8.2.2.26-CUDA-11.4.1 \\n            conda activate dex \\n            export MKL_NUM_THREADS=1 \\n            export NUMEXPR_NUM_THREADS=1 \\n            export OMP_NUM_THREADS=1 \\n            export OPENBLAS_NUM_THREADS=1\\n            pwd\\n            nvidia-smi\\n            mv_cmd = f'mv /home/amawi/projects/hwat/exp/tmp/o-$SLURM_JOB_ID.out /home/amawi/projects/hwat/exp/tmp/e-$SLURM_JOB_ID.err $out_dir' \\n    \"},\n",
       " 'project_path': PosixPath('/home/amawi/projects/hwat'),\n",
       " 'server_project_path': PosixPath('/home/amawi/projects/hwat'),\n",
       " 'n_device': 2,\n",
       " 'iter_exp_dir': False,\n",
       " 'exp_path': PosixPath('/home/amawi/projects/hwat/exp/demo/2SbUE9h'),\n",
       " 'project_exp_dir': PosixPath('/home/amawi/projects/hwat/exp'),\n",
       " 'project_cfg_dir': PosixPath('/home/amawi/projects/hwat/cfg'),\n",
       " 'TMP': PosixPath('/home/amawi/projects/hwat/exp/tmp'),\n",
       " 'server': 'svol.fysik.dtu.dk',\n",
       " 'user': 'amawi',\n",
       " 'entity': 'xmax1',\n",
       " 'git_remote': 'origin',\n",
       " 'git_branch': 'main',\n",
       " 'env': 'dex',\n",
       " 'submit_state': -1,\n",
       " 'commit_id': '05e8bf7',\n",
       " 'merge': <bound method Pyfig.merge of <pyfig.Pyfig object at 0x7f68802c06d0>>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'ShardedDeviceArray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# vars(state)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m jax\u001b[39m.\u001b[39;49mdevices(state\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/.conda/envs/dex/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py:483\u001b[0m, in \u001b[0;36mdevices\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdevices\u001b[39m(backend: Optional[Union[\u001b[39mstr\u001b[39m, XlaBackend]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[xla_client\u001b[39m.\u001b[39mDevice]:\n\u001b[1;32m    461\u001b[0m   \u001b[39m\"\"\"Returns a list of all devices for a given backend.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[39m  .. currentmodule:: jaxlib.xla_extension\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39m    List of Device subclasses.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m   \u001b[39mreturn\u001b[39;00m get_backend(backend)\u001b[39m.\u001b[39mdevices()\n",
      "File \u001b[0;32m~/.conda/envs/dex/lib/python3.10/site-packages/flax/core/frozen_dict.py:107\u001b[0m, in \u001b[0;36mFrozenDict.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m   h \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    106\u001b[0m   \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 107\u001b[0m     h \u001b[39m^\u001b[39m\u001b[39m=\u001b[39m \u001b[39mhash\u001b[39;49m((key, value))\n\u001b[1;32m    108\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash \u001b[39m=\u001b[39m h\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash\n",
      "File \u001b[0;32m~/.conda/envs/dex/lib/python3.10/site-packages/flax/core/frozen_dict.py:107\u001b[0m, in \u001b[0;36mFrozenDict.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m   h \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    106\u001b[0m   \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 107\u001b[0m     h \u001b[39m^\u001b[39m\u001b[39m=\u001b[39m \u001b[39mhash\u001b[39;49m((key, value))\n\u001b[1;32m    108\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash \u001b[39m=\u001b[39m h\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'ShardedDeviceArray'"
     ]
    }
   ],
   "source": [
    "# vars(state)\n",
    "jax.devices(state.params['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting:  n_e 6\n",
      "setting:  n_u 3\n",
      "setting:  n_b 4\n",
      "setting:  n_sv 8\n",
      "setting:  n_pv 8\n",
      "setting:  corr_len 2\n",
      "setting:  n_step 20\n",
      "setting:  log_metric_step 5\n",
      "setting:  exp_name debug\n",
      "0 args unmerged: ✅\n",
      "Path:  /home/amawi/projects/hwat/exp/debug/HMJuihb ✅\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wllr09zv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61211979a4f8467fb6b61b0506c1d930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cosmic-feather-61</strong>: <a href=\"https://wandb.ai/xmax1/hwat/runs/wllr09zv\" target=\"_blank\">https://wandb.ai/xmax1/hwat/runs/wllr09zv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./exp/demo-final/lWGRdMF/wandb/run-20221130_104112-wllr09zv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wllr09zv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001983fbddcb404bb3d06ee9628a1eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669371665921064, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/amawi/projects/hwat/exp/debug/HMJuihb/wandb/run-20221130_104209-1gl2w1yz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xmax1/hwat/runs/1gl2w1yz\" target=\"_blank\">good-pine-62</a></strong> to <a href=\"https://wandb.ai/xmax1/hwat\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:  xmax1/hwat/1gl2w1yz ✅\n",
      "Pyfig ✅\n",
      "Train Step ✅\n",
      "Init: x (2, 4, 6, 3) rng (2, 2) ✅\n",
      "Model ✅\n",
      "Equil ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 11:08:38.101708: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] \n",
      "********************************\n",
      "[Compiling module pmap_equil] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "2022-11-30 11:14:29.475447: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 7m51.372586518s\n",
      "\n",
      "********************************\n",
      "[Compiling module pmap_equil] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walkers ✅ Training Variables ✅\n",
      "Update ✅\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pyfig' object has no attribute 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [44], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (step \u001b[39m%\u001b[39m c\u001b[39m.\u001b[39mlog_state_step):\n\u001b[1;32m    110\u001b[0m         \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGo seek: \u001b[39m\u001b[39m'\u001b[39m, c\u001b[39m.\u001b[39;49mwandb\u001b[39m.\u001b[39mrun_path)\n\u001b[1;32m    113\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pyfig' object has no attribute 'wandb'"
     ]
    }
   ],
   "source": [
    "from utils import flat_any\n",
    "# import time\n",
    "# from multiprocess import Manager, Process, Value\n",
    "\n",
    "# manager = Manager()\n",
    "# list1 = manager.list([\"a\"])\n",
    "# go = Value('b', True)\n",
    "\n",
    "# def worker(list1, go):\n",
    "#     while go.value:\n",
    "#         time.sleep(1)\n",
    "#         print(list1)\n",
    "#     return\n",
    "\n",
    "# p = Process(target=worker, args=(list1, go))\n",
    "# p.start()\n",
    "\n",
    "debug_args = {'n_e': 6,'n_u': 3,'n_b': 4, 'n_sv': 8, 'n_pv': 8, 'corr_len': 2, 'n_step': 20,'log_metric_step': 5,'exp_name':'debug'}\n",
    "class arg_cls(Pyfig):\n",
    "    def __init__(_i):\n",
    "        pass\n",
    "arg_cls.data.n_e = 6\n",
    "arg_cls.data.n_u = 6\n",
    "arg_cls.data.n_b = 6\n",
    "arg_cls.n_step = 20\n",
    "arg_cls.log_metric_step = 5\n",
    "arg_cls.exp_name = 'demo'\n",
    "\n",
    "args = flat_any(arg_cls().d)\n",
    "\n",
    "c = Pyfig(wandb_mode='online', args=debug_args, get_sys_arg=False)\n",
    "print('Pyfig ✅')\n",
    "\n",
    "part_sample = partial(sample, acc_target=c.data.acc_target)\n",
    "\n",
    "@partial(pmap, in_axes=(0, 0, 0, 0))\n",
    "def train_step(rng, state, x, deltar):\n",
    "    x, v_sam = part_sample(rng, state, x, deltar)\n",
    "\n",
    "    pe = partial(PotentialEnergy(a=c.data.a, a_z=c.data.a_z).apply, {})(x)\n",
    "    ke = compute_ke_b(state, x)\n",
    "    e = pe + ke\n",
    "\n",
    "    def loss(_params):\n",
    "        return (e * state.apply_fn(_params, x)).sum()\n",
    "    \n",
    "    grads = grad(loss)(state.params)\n",
    "\n",
    "    v = dict(\n",
    "        grads=grads,\n",
    "        pe=pe,\n",
    "        ke=ke,\n",
    "        e=e,\n",
    "        deltar=v_sam['deltar'],\n",
    "        rng=rng,\n",
    "        x=x,\n",
    "        acc=v_sam['acc']\n",
    "    )\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, v\n",
    "print('Train Step ✅')\n",
    "\n",
    "rng = c.rng_init\n",
    "x = c.data.init_walker(rng, n_b=c.data.n_b)\n",
    "deltar = jnp.ones((c.n_device, 1), dtype=x.dtype)*0.02\n",
    "print(f'Init: x {x.shape} rng {rng.shape} ✅')\n",
    "\n",
    "@partial(jax.pmap, axis_name='b', in_axes=(0,0))\n",
    "def create_train_state(rng, x):\n",
    "    model = c.partial(FermiNet)  \n",
    "    params = model.init(rng, x)\n",
    "    state = TrainState.create(apply_fn=model.apply, params=params, tx=c.opt.tx)\n",
    "    return state\n",
    "\n",
    "state = create_train_state(rng, x)\n",
    "print('Model ✅')\n",
    "\n",
    "@partial(jax.pmap, axis_name='b', in_axes=(0,0,0,0))\n",
    "def equil(rng, state, x, deltar):\n",
    "    for _ in range(10):\n",
    "        x, v_sam = part_sample(rng, state, x, deltar)\n",
    "        rng, deltar = v_sam['rng'], v_sam['deltar']\n",
    "    return x, v_sam\n",
    "print('Equil ✅')\n",
    "\n",
    "wandb.define_metric(\"*\", step_metric=\"eq/step\")\n",
    "for step in range(1, 501):\n",
    "    x, v_sam = equil(rng, state, x, deltar)\n",
    "    rng, deltar, acc = v_sam['rng'], v_sam['deltar'], v_sam['acc']\n",
    "    if not (step % c.log_metric_step):\n",
    "        wandb.log({'eq/step':step, **v_sam})\n",
    "print('Walkers ✅ Training Variables ✅')\n",
    "\n",
    "@jax.pmap\n",
    "def update_model(state, grads):\n",
    "  return state.apply_gradients(grads=grads)\n",
    "print('Update ✅')\n",
    "\n",
    "wandb.define_metric(\"*\", step_metric=\"tr/step\")\n",
    "for step in range(1, c.n_step+1):\n",
    "    state, data = train_step(rng, state, x, deltar)\n",
    "    rng, deltar, x, grads = data['rng'], data['deltar'], data['x'], data['grads']\n",
    "\n",
    "    if not (step % c.log_metric_step):\n",
    "        metrix = compute_metrix(data)\n",
    "        wandb.log({'tr/step':step, **metrix})\n",
    "        m = ' '.join([f'{k} {v:.5f} ' for k,v in metrix.items() if 'E_' in k])\n",
    "\n",
    "    if not (step % c.log_state_step):\n",
    "        ...\n",
    "\n",
    "print('Go seek: ', c.wandb_c.wandb_run_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipyparallel.readthedocs.io/en/latest/\n",
    "\n",
    "%wandb c.wandb_c.wandb_run_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💓 \n",
    "class tr_data:\n",
    "    x:jnp.ndarray=x\n",
    "    rng:jnp.ndarray=rng"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
