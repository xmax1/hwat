{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False True\n",
      "[CompletedProcess(args=['git', 'add', '.'], returncode=0, stdout=b'', stderr=b''), CompletedProcess(args=['git', 'commit', '-m', 'run_things'], returncode=0, stdout=b'[main c90efce] run_things\\n Committer: Adam Maximilian Wilson <amawi@oceanus.imm.dtu.dk>\\nYour name and email address were configured automatically based\\non your username and hostname. Please check that they are accurate.\\nYou can suppress this message by setting them explicitly. Run the\\nfollowing command and follow the instructions in your editor to edit\\nyour configuration file:\\n\\n    git config --global --edit\\n\\nAfter doing this, you may fix the identity used for this commit with:\\n\\n    git commit --amend --reset-author\\n\\n 2 files changed, 15 insertions(+), 8 deletions(-)\\n', stderr=b''), CompletedProcess(args=['git', 'push'], returncode=0, stdout=b'', stderr=b'To github.com:xmax1/hwat.git\\n   381f69c..c90efce  main -> main\\n')]\n",
      "svol.fysik.dtu.dk amawi python -u /home/amawi/projects/hwat/run.py c90efce --project_root  /home/amawi/projects   --project  hwat   --data_dir  /home/amawi/projects/data   --run_path  /home/amawi/projects/hwat/run.py   --exp_name  junk   --exp_id  sEBXPIZ   --sweep_id     --seed  808017424   --dtype  float32   --n_step  10000   --log_metric_step  50   --log_state_step  10   --charge  0   --spin  0   --a  [[0. 0. 0.]]   --a_z  [4.]   --n_e  4   --n_u  2   --n_d  2   --n_b  512   --n_corr  20   --n_equil  10000   --acc_target  0.5   --with_sign  False   --n_sv  32   --n_pv  32   --n_fbv  160   --n_fb  2   --n_det  1   --terms_s_emb  ['ra', 'ra_len']   --terms_p_emb  ['rr', 'rr_len']   --job_type  training   --entity  hwat   --wandb_run_path     --mail_type  FAIL   --partition  sm3090   --nodes  1   --ntasks  8   --cpus_per_task  1   --time  0-12:00:00   --gres  gpu:RTX3090:1   --output  dump/tmp/o-%j.out   --error  dump/tmp/e-%j.err   --job_name  junk   --sbatch   \n",
      "            module purge \n",
      "            source ~/.bashrc \n",
      "            module load GCC \n",
      "            module load CUDA/11.4.1 \n",
      "            module load cuDNN/8.2.2.26-CUDA-11.4.1 \n",
      "            conda activate dex \n",
      "            export MKL_NUM_THREADS=1 \n",
      "            export NUMEXPR_NUM_THREADS=1 \n",
      "            export OMP_NUM_THREADS=1 \n",
      "            export OPENBLAS_NUM_THREADS=1\n",
      "            pwd\n",
      "            nvidia-smi\n",
      "            mv_cmd = f'mv dump/tmp/o-$SLURM_JOB_ID.out dump/tmp/e-$SLURM_JOB_ID.err $out_dir'\n",
      "            out_dir=/home/amawi/projects/hwat/exp/junk/sEBXPIZ/out\n",
      "               --TMP  dump/tmp   --project_path  /home/amawi/projects/hwat   --server_project_path  /home/amawi/projects/hwat   --n_device  1   --exp_path  /home/amawi/projects/hwat/exp/junk/sEBXPIZ   --server  svol.fysik.dtu.dk   --user  amawi   --git_remote  origin   --git_branch  main   --env  dex   --merge  <bound method Pyfig.merge of <pyfig.Pyfig object at 0x7f8a1f42b940>>   --commit_id  c90efce  /home/amawi/projects/hwat\n",
      "[(<paramiko.ChannelFile from <paramiko.Channel 1 (closed) -> <paramiko.Transport at 0xdd6ded0 (unconnected)>>>, <paramiko.ChannelFile from <paramiko.Channel 1 (closed) -> <paramiko.Transport at 0xdd6ded0 (unconnected)>>>, <paramiko.ChannelFile from <paramiko.Channel 1 (closed) -> <paramiko.Transport at 0xdd6ded0 (unconnected)>>>)]\n",
      "ü§ñ 1 GPUs available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' copy lines and run in analysis while the exp is live '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Distribution ‚ú® ‚ùá Demo üí™ ### \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "### fancy logging variables, philosophically reminding us of the goal ###\n",
    "fancy = dict(\n",
    "\t\tpe\t\t= r'$V(X)',    \t\t\t\t\n",
    "\t\tke\t\t= r'$\\nabla^2',    \t\t\n",
    "\t\te\t\t= r'$E',\t\t\t\t\t\t\n",
    "\t\tlog_psi\t= r'$\\log\\psi', \t\t\t\n",
    "\t\tdeltar\t= r'$\\delta_\\mathrm{r}',\t\n",
    "\t\tx\t\t= r'$r_\\mathrm{e}',\n",
    ")\n",
    "\n",
    "### pyfig ###\n",
    "from pyfig import Pyfig\n",
    "import numpy as np\n",
    "\n",
    "arg = dict(\n",
    "\tcharge = 0,\n",
    "\tspin  = 0,\n",
    "\ta = np.array([[0.0, 0.0, 0.0],]),\n",
    "\ta_z  = np.array([4.,]),\n",
    "\tn_b = 512, \n",
    "\tn_sv = 32, \n",
    "\tn_pv = 32, \n",
    "\tn_corr = 20, \n",
    "\tn_step = 10000, \n",
    "\tlog_metric_step = 50, \n",
    "\texp_name = 'junk',\n",
    "\t# sweep = {},\n",
    ")\n",
    "\n",
    "c = Pyfig(wandb_mode='online', arg=arg, submit=True)\n",
    "\n",
    "n_device = c.n_device\n",
    "print(f'ü§ñ {n_device} GPUs available')\n",
    "\n",
    "\n",
    "\"\"\" live plotting in another notebook \"\"\"\n",
    "\"\"\" copy lines and run in analysis while the exp is live \"\"\"\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<run-here>\")\n",
    "# c = run.config\n",
    "# h = run.history()\n",
    "# s = run.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp/actual | \n",
      "\trng    : (2,)/(2,) \n",
      "\trng_p  : (1, 2)/(1, 2) \n",
      "\tcps    : (4, 3)/(4, 3)\n",
      "\tr      : (1, 512, 4, 3)/(1, 512, 4, 3)\n",
      "\tdeltar : (1, 1)/(1, 1)\n",
      "\n",
      "path exists, leaving alone\n"
     ]
    }
   ],
   "source": [
    "### model (aka TrainState) ### \n",
    "from functools import partial\n",
    "import jax\n",
    "import optax\n",
    "from flax.training.train_state import TrainState\n",
    "from hwat import FermiNet\n",
    "\n",
    "@partial(jax.pmap, axis_name='dev', in_axes=(0,0))\n",
    "def create_train_state(rng, r):\n",
    "\tmodel = c.partial(FermiNet)\n",
    "\tparams = model.init(rng, r)\n",
    "\topt = optax.chain(optax.clip_by_block_rms(1.),optax.adamw(0.001))\n",
    "\treturn TrainState.create(apply_fn=model.apply, params=params, tx=opt)\n",
    "\n",
    "\n",
    "### train step ###\n",
    "from jax import numpy as jnp\n",
    "from hwat import compute_ke_b, compute_pe_b\n",
    "from typing import NamedTuple\n",
    "\n",
    "@partial(jax.pmap, in_axes=(0, 0))\n",
    "def train_step(state, r_step):\n",
    "\n",
    "\tke = compute_ke_b(state, r_step)\n",
    "\tpe = compute_pe_b(r_step, c.data.a, c.data.a_z)\n",
    "\te = pe + ke\n",
    "\t\n",
    "\te_mean_dist = jnp.mean(jnp.abs(jnp.median(e) - e))\n",
    "\te_clip = jnp.clip(e, a_min=e-5*e_mean_dist, a_max=e+5*e_mean_dist)\n",
    "\n",
    "\tdef loss(params):\n",
    "\t\treturn ((e_clip - e_clip.mean())*state.apply_fn(params, r_step)).mean()\n",
    "\t\n",
    "\tgrads = jax.grad(loss)(state.params)\n",
    "\tstate = state.apply_gradients(grads=grads)\n",
    "\t\n",
    "\tv_tr = dict(\n",
    "\t\tparams=state.params, grads=grads,\n",
    "\t\te=e, pe=pe, ke=ke,\n",
    "\t\tr=r_step\n",
    "\t)\n",
    "\n",
    "\treturn state, v_tr\n",
    "\n",
    "\n",
    "### init variables ###\n",
    "from utils import gen_rng\n",
    "from hwat import init_r, get_center_points\n",
    "from jax import random as rnd\n",
    "\n",
    "rng, rng_p = gen_rng(rnd.PRNGKey(c.seed), c.n_device)\n",
    "center_points = get_center_points(c.data.n_e, c.data.a)\n",
    "r = init_r(rng_p, c.data.n_b, c.data.n_e, center_points, std=0.1)\n",
    "deltar = jnp.array([0.02])[None, :].repeat(n_device, axis=0)\n",
    "\n",
    "print(f\"\"\"exp/actual | \n",
    "\trng    : {(2,)}/{rng.shape} \n",
    "\trng_p  : {(c.n_device,2)}/{rng_p.shape} \n",
    "\tcps    : {(c.data.n_e,3)}/{center_points.shape}\n",
    "\tr      : {(c.n_device, c.data.n_b, c.data.n_e, 3)}/{r.shape}\n",
    "\tdeltar : {(c.n_device, 1)}/{deltar.shape}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "### init functions ### \n",
    "from hwat import sample_b\n",
    "\n",
    "state = create_train_state(rng_p, r)\n",
    "metro_hast = jax.pmap(partial(sample_b, n_corr=c.data.n_corr), in_axes=(0,0,0,0))\n",
    "\n",
    "\n",
    "### train ###\n",
    "import wandb\n",
    "from hwat import keep_around_points\n",
    "from utils import compute_metrix\n",
    "\n",
    "wandb.define_metric(\"*\", step_metric=\"tr/step\")\n",
    "for step in range(1, c.n_step+1):\n",
    "\trng, rng_p = gen_rng(rng, c.n_device)\n",
    "\n",
    "\tr, acc, deltar = metro_hast(rng_p, state, r, deltar)\n",
    "\tr = keep_around_points(r, center_points, l=2.) if step < 1000 else r\n",
    "\t\n",
    "\tstate, v_tr = train_step(state, r)\n",
    "\n",
    "\tif not (step % c.log_metric_step):\n",
    "\t\tmetrix = compute_metrix(v_tr)\n",
    "\t\twandb.log({'tr/step':step, **metrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ```{toggle} env vars and jax debug config notes\n",
    "# ‚ùáÔ∏è Magic & debug not currently used\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %env CUDA_VISIBLE_DEVICES='3'\n",
    "# %env \"WANDB_NOTEBOOK_NAME\" \"run.ipynb\" # ‚ùïsame as notebook\n",
    "\n",
    "# from jax.config import config\n",
    "# config.update('jax_disable_jit', True)\n",
    "# ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
