{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from jax.config import config\n",
    "config.update('jax_disable_jit', True)\n",
    "\n",
    "from jax import random as rnd, numpy as jnp\n",
    "from functools import partial\n",
    "import jax\n",
    "from flax.training.train_state import TrainState\n",
    "import optax\n",
    "\n",
    "from pyfig import Pyfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "- Steps and general JAX implementation details\n",
    "- pmap across devices\n",
    "- Run train loop \n",
    "- Submit to cluster\n",
    "- Live results analysis\n",
    "- gist demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 15:00:54.832153: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:497] The NVIDIA driver's CUDA version is 11.4 which is older than the ptxas CUDA version (11.6.55). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "c = Pyfig(wandb_mode='disabled')\n",
    "# pprint(c.d)\n",
    "rng = rnd.PRNGKey(c.seed)\n",
    "x = c.data.init_walker(rng, n_b=4)\n",
    "# from hwat import init_walker\n",
    "# x = init_walker(rng, c.data.n_b, c.data.n_u, c.data.n_d, center=c.data.a, std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ -8.076733, -13.017015, -11.022902, -12.247166], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hwat import FermiNet\n",
    "model = c.partial(FermiNet)\n",
    "vars = model.init(rng, x)  # {'params':p, ... other variables if they exist}\n",
    "model.apply(vars, x)       # potentially the only way to run something in jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apply_fn', 'apply_gradients', 'create', 'opt_state', 'params', 'replace', 'step', 'tx']\n"
     ]
    }
   ],
   "source": [
    "def create_train_state(rng):\n",
    "    x = c.data.init_walker(rng, n_b=4)\n",
    "    model = c.partial(FermiNet)\n",
    "    params = model.init(rng, x)\n",
    "    tx = optax.sgd(c.opt.lr)\n",
    "    return TrainState.create(\n",
    "        apply_fn=model.apply, \n",
    "        params=params, \n",
    "        tx=tx\n",
    "    )\n",
    "\n",
    "state = create_train_state(rng)\n",
    "print([v for v in dir(state) if not v.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['deltar', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "from hwat import sample\n",
    "\n",
    "deltar = jnp.array([0.02])\n",
    "x, v_b = sample(rng, state, x, deltar)\n",
    "print(v_b.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -74.084564  -66.35562  -141.6063   -145.27791 ]\n"
     ]
    }
   ],
   "source": [
    "from hwat import PotentialEnergy\n",
    "\n",
    "compute_pe = partial(PotentialEnergy(a=c.data.a, a_z=c.data.a_z).apply, {})\n",
    "print(compute_pe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhwat\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_ke_b\n\u001b[0;32m----> 3\u001b[0m compute_ke_b(state, x)\n",
      "File \u001b[0;32m~/projects/hwat/hwat.py:208\u001b[0m, in \u001b[0;36mcompute_ke_b\u001b[0;34m(state, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_ke_b\u001b[39m(state, x):\n\u001b[0;32m--> 208\u001b[0m     n_b, n_e, _ \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m    210\u001b[0m     partial_state \u001b[39m=\u001b[39m partial(state\u001b[39m.\u001b[39mapply_fn, state\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    211\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: partial_state(x)\u001b[39m.\u001b[39msum()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from hwat import compute_ke_b\n",
    "    \n",
    "compute_ke_b(state, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
