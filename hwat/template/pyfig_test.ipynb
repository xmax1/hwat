{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "path exists, leaving alone\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def mkdir(path: Path) -> Path:\n",
    "    path = Path(path)\n",
    "    if path.suffix != '':\n",
    "        path = path.parent\n",
    "    if path.exists():\n",
    "        print('path exists, leaving alone')\n",
    "    else:\n",
    "        path.mkdir(parents=True)\n",
    "    return path\n",
    "\n",
    "this_dir = Path('').parent\n",
    "TMP = mkdir('./tmp/out')\n",
    "\n",
    "import paramiko\n",
    "import sys\n",
    "import subprocess\n",
    "import wandb\n",
    "from time import sleep\n",
    "from functools import partial, reduce\n",
    "from itertools import product\n",
    "from simple_slurm import Slurm\n",
    "import random\n",
    "from typing import Any, Iterable\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "def get_cartesian_product(*args):\n",
    "    \"\"\" Cartesian product is the ordered set of all combinations of n sets \"\"\"\n",
    "    return list(product(*args))\n",
    "\n",
    "def zip_in_n_chunks(arg: Iterable[Any], n: int) -> zip:   \n",
    "    return zip(*([iter(arg)]*n))\n",
    "\n",
    "def flat_list(lst_of_lst):\n",
    "    return [lst for sublst in lst_of_lst for lst in sublst]\n",
    "\n",
    "def gen_alphanum(n: int = 7, test=False):\n",
    "    from string import ascii_lowercase, ascii_uppercase\n",
    "    random.seed(test if test else None)\n",
    "    numbers = ''.join([str(i) for i in range(10)])\n",
    "    characters = ascii_uppercase + ascii_lowercase + numbers\n",
    "    name = ''.join([random.choice(characters) for _ in range(n)])\n",
    "    return name\n",
    "\n",
    "def add_to_Path(path: Path, string: str | Path):\n",
    "        return Path(str(path) + str(string))\n",
    "\n",
    "def iterate_folder(folder: Path, iter_exp_dir):\n",
    "    if iter_exp_dir and folder.exists():\n",
    "        for i in range(100):\n",
    "            _folder = add_to_Path(folder, f'-{i}')\n",
    "            if not re.search(_folder.name, f'-[0-9]*'):\n",
    "                folder = _folder\n",
    "                break\n",
    "        else:\n",
    "            folder = add_to_Path(folder, f'-0')\n",
    "    return folder\n",
    "\n",
    "class Sub:\n",
    "    \n",
    "    def __init__(_i, parent=None):\n",
    "        _i.parent = parent\n",
    "        _i.__safe_init__()\n",
    "\n",
    "    def __safe_init__(_i):\n",
    "        cls_d = dict(_i.__class__.__dict__)\n",
    "        sub_cls = {k:v for k,v in cls_d.items() if isinstance(v, type)}\n",
    "        [cls_d.pop(k) for k in sub_cls.keys()]\n",
    "        for k,v in cls_d.items():\n",
    "            # print(k, type(v), callable(v))\n",
    "            if k.startswith('__') or k in Pyfig._ignore_attr:\n",
    "                continue # this was around because 'dicts are unhashable types'\n",
    "            if callable(v) or isinstance(v, property):\n",
    "                continue\n",
    "            setattr(_i, k, v)\n",
    "        [setattr(_i, k, v(parent=_i)) for k,v in sub_cls.items()]\n",
    "\n",
    "    @property\n",
    "    def dict(_i,):\n",
    "        d = cls_to_dict(_i, Pyfig._ignore_attr)\n",
    "        for k,v in d.items():\n",
    "            if issubclass(type(v), Sub):\n",
    "                d[k] = cls_to_dict(v, Pyfig._ignore_attr)\n",
    "        return d\n",
    "\n",
    "def cls_to_dict(cls, ignore:list)->dict:\n",
    "    d = {}\n",
    "    for k,v in cls.__dict__.items():\n",
    "        if k.startswith('_') or k in ignore:\n",
    "            continue\n",
    "        if callable(v):\n",
    "            continue\n",
    "        if issubclass(type(v), Sub):\n",
    "            d[k] = cls_to_dict(v, ignore)\n",
    "            continue\n",
    "        d[k] = getattr(cls,k)\n",
    "    return d\n",
    "\n",
    "def cmd_to_dict(cmd:str|list,ref:dict,_d={},delim:str=' --'):\n",
    "    \"\"\"\n",
    "    fmt: [--flag, arg, --true_flag, --flag, arg1]\n",
    "    # all flags double dash because of negative numbers duh \"\"\"\n",
    "    booleans = ['True', 'true', 't', 'False', 'false', 'f']\n",
    "    \n",
    "    cmd = ' '.join(cmd) if isinstance(cmd, list) else cmd\n",
    "    cmd = [x.lstrip().lstrip('--').rstrip() for x in cmd.split(delim)]\n",
    "    cmd = [x.split(' ', maxsplit=1) for x in cmd if ' ' in x]\n",
    "    [x.append('True') for x in cmd if len(x) == 1]\n",
    "    cmd = flat_list(cmd)\n",
    "    cmd = iter([x.strip() for x in cmd])\n",
    "\n",
    "    for k,v in zip(cmd, cmd):\n",
    "        if v in booleans: \n",
    "            v=booleans.index(v)<3  # 0-2 True 3-5 False\n",
    "        if k in ref:\n",
    "            _d[k] = type(ref[k])(v)\n",
    "        else:\n",
    "            try:\n",
    "                _d[k] = literal_eval(v)\n",
    "            except:\n",
    "                _d[k] = str(v)\n",
    "            print(f'Guessing type: {k} as {type(v)}')\n",
    "    return _d\n",
    "\n",
    "def update_cls_with_dict(cls: Any, d:dict):\n",
    "    cls_all = [v for v in cls.__dict__.values() if issubclass(type(v), Sub)]\n",
    "    cls_all.extend([cls])\n",
    "    n_remain = len(d)\n",
    "    for k,v in d.items():\n",
    "        for _cls_assign in cls_all:            \n",
    "            if not hasattr(_cls_assign, k):\n",
    "                continue\n",
    "            else:\n",
    "                if isinstance(cls.__class__.__dict__[k], property):\n",
    "                    print('Tried to assign property, consider your life choices')\n",
    "                    continue\n",
    "                v = type(cls.__dict__)(v)\n",
    "                setattr(_cls_assign, k, v)\n",
    "                n_remain -= 1\n",
    "    return n_remain\n",
    "\n",
    "def cls_to_dict(cls, ignore:list)->dict:\n",
    "    return {k: getattr(cls, k) for k in dir(cls) if not (k.startswith('_') or k in ignore)}\n",
    "\n",
    "def flat_dict(d:dict,items:list=[]):\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flat_dict(v, items=items).items())\n",
    "        else:\n",
    "            items.append((k, v))\n",
    "    return dict(items)  \n",
    "\n",
    "def dict_to_wandb(d:dict,parent_key:str='',sep:str ='.',items:list=[])->dict:\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict): \n",
    "            items.extend(dict_to_wandb(v,new_key,items=items).items())\n",
    "        else:\n",
    "            if isinstance(v, Path):  v=str(v)\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def count_gpu() -> int: # output = run_cmd('echo $CUDA_VISIBLE_DEVICES', cwd='.')\n",
    "    return sum(c.isdigit() for c in os.environ.get('CUDA_VISIBLE_DEVICES'))\n",
    "\n",
    "def run_cmds(cmd:str|list,cwd:str|Path=None,input_req:str=None):\n",
    "    _out = []\n",
    "    for cmd_1 in (cmd if isinstance(cmd, list) else [cmd]): \n",
    "        cmd_1 = [c.strip() for c in cmd_1.split(' ')]\n",
    "        _out += [subprocess.run(\n",
    "            cmd_1,cwd=cwd,input=input_req, capture_output=True)]\n",
    "        sleep(0.1)\n",
    "    return _out\n",
    "\n",
    "def run_cmds_server(server:str,user:str,cmd:str|list,cwd=str|Path):\n",
    "    _out = []\n",
    "    client = paramiko.SSHClient()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())  # if not known host\n",
    "    client.connect(hostname=server, username=user)\n",
    "    client.exec_command(f'cd {cwd}')\n",
    "    with client as _r:\n",
    "        for cmd_1 in (cmd if isinstance(cmd, list) else [cmd]):\n",
    "            _out += [_r.exec_command(f'{cmd_1}')] # in, out, err\n",
    "            sleep(0.1)\n",
    "    return _out\n",
    "\n",
    "class Pyfig(Sub):\n",
    "\n",
    "    seed:               int     = 808017424 # grr\n",
    "    project_root:       str     = Path().home()/'projects'\n",
    "\n",
    "    project:            str     = 'hwat'\n",
    "    project_path:       Path    = property(lambda _: _.project_root / _.project)\n",
    "    server_project_path:Path    = property(lambda _: _.project_path)\n",
    "    n_device:           int     = property(lambda _: count_gpu())\n",
    "\n",
    "    exp_name:           str     = 'junk'\n",
    "    run_path:           Path    = property(lambda _: _.project_path / 'run.py')\n",
    "    data_dir:           Path    = project_root / 'data'\n",
    "    \n",
    "    half_precision:     bool    = True\n",
    "    dtype:              str     = 'f32'\n",
    "    n_step:             int     = 1000\n",
    "\n",
    "    af:                 str     = 'tanh' # activation function\n",
    "    n_layer:            int     = 3\n",
    "    \n",
    "    class data(Sub):\n",
    "        dataset     = 'fashion_mnist'\n",
    "        b_size      = 16\n",
    "        cache       = False\n",
    "        image_size  = 28\n",
    "        channels    = 1\n",
    "\n",
    "    class model(Sub):\n",
    "        dim         = 64\n",
    "        dim_mults   = (1, 2, 4)\n",
    "\n",
    "    class opt(Sub):\n",
    "        optimizer   = 'Adam'\n",
    "        beta1       = 0.9\n",
    "        beta2       = 0.99\n",
    "        eps         = 1e-8\n",
    "        lr          = 0.001\n",
    "        loss        = 'l1'  # change this to loss table load? \n",
    "\n",
    "    class sweep(Sub):\n",
    "        method      = 'random'\n",
    "        name        = 'sweep'\n",
    "        metrics = dict(\n",
    "            goal    = 'minimize',\n",
    "            name    = 'validation_loss',\n",
    "        )\n",
    "        parameters = dict(\n",
    "            batch_size  = {'values' : [16, 32, 64]},\n",
    "            epoch       = {'values' : [5, 10, 15]},\n",
    "            lr          = {'max'    : 0.1, 'min': 0.0001},\n",
    "        )\n",
    "        n_sweep = run_cap = reduce(\n",
    "            lambda i,j:i*j,[len(v['values']) for k,v in parameters.items() if 'values' in v])+1\n",
    "        sweep_id = ''\n",
    "\n",
    "    class wandb(Sub):\n",
    "        job_type:       str     = 'training'\n",
    "        entity:         str     = 'xmax1'\n",
    "\n",
    "    log_sample_step:    int     = 5\n",
    "    log_metric_step:    int     = 5\n",
    "    log_state_step:     int     = 10         # wandb entity\n",
    "    n_epoch:            int     = 20\n",
    "\n",
    "    class slurm(Sub):\n",
    "        output          = TMP/'o-%j.out'\n",
    "        error           = TMP/'e-%j.err'\n",
    "        mail_type       = 'FAIL'\n",
    "        partition       ='sm3090'\n",
    "        nodes           = 1                # n_node\n",
    "        ntasks          = 8                # n_cpu\n",
    "        cpus_per_task   = 1     \n",
    "        time            = '0-12:00:00'     # D-HH:MM:SS\n",
    "        gres            = 'gpu:RTX3090:1'\n",
    "        job_name        = property(lambda _: _.parent.exp_name)  # this does not call the instance it is in\n",
    "        sbatch          = property(lambda _: f\"\"\" \n",
    "            module purge \n",
    "            source ~/.bashrc \n",
    "            module load GCC \n",
    "            module load CUDA/11.4.1 \n",
    "            module load cuDNN/8.2.2.26-CUDA-11.4.1 \n",
    "            conda activate {_.parent.env} \n",
    "            export MKL_NUM_THREADS=1 \n",
    "            export NUMEXPR_NUM_THREADS=1 \n",
    "            export OMP_NUM_THREADS=1 \n",
    "            export OPENBLAS_NUM_THREADS=1\n",
    "            pwd\n",
    "            nvidia-smi\n",
    "            mv_cmd = f'mv {TMP}/o-$SLURM_JOB_ID.out {TMP}/e-$SLURM_JOB_ID.err $out_dir' \n",
    "    \"\"\")\n",
    "\n",
    "    exp_id:             str     = gen_alphanum(n=7)\n",
    "    \n",
    "    iter_exp_dir:       bool    = True\n",
    "    project_exp_dir:    Path    = property(lambda _: _.project_path / 'exp')\n",
    "    project_cfg_dir:    Path    = property(lambda _: _.project_path / 'cfg')\n",
    "    exp_path:           Path    = property(lambda _: iterate_folder(_.project_exp_dir/_.exp_name,_.iter_exp_dir)/_.exp_id)\n",
    "\n",
    "    server:             str     = 'svol.fysik.dtu.dk'   # SERVER\n",
    "    user:               str     = 'amawi'     # SERVER\n",
    "    entity:             str     = 'xmax1'       # WANDB entity\n",
    "    git_remote:         str     = 'origin'      \n",
    "    git_branch:         str     = 'main'        \n",
    "    env:                str     = 'dex'            # CONDA ENV\n",
    "    commit_id:          str     = property(lambda _: _.get_commit_id())\n",
    "    \n",
    "    _sys_arg: list = sys.argv[1:]\n",
    "    _submit_state:     int     = -1\n",
    "    _ignore_attr = ['parent','protected','dict','cmd']\n",
    "\n",
    "    def __init__(_i,args:dict={},cap=40,wandb_mode='online',notebook=False):\n",
    "        super().__init__()\n",
    "        _i.__safe_init__()\n",
    "\n",
    "        update_cls_with_dict(_i,args)\n",
    "        if not notebook:\n",
    "            update_cls_with_dict(cmd_to_dict(sys.argv[1:],_i.dict))\n",
    "\n",
    "        wandb.init(\n",
    "            job_type    = _i.wandb.job_type,\n",
    "            entity      = _i.wandb.entity,\n",
    "            project     = _i.project,\n",
    "            dir         = _i.exp_path,\n",
    "            config      = dict_to_wandb(_i.dict),\n",
    "            mode        = wandb_mode,\n",
    "            settings=wandb.Settings(start_method='fork'), # idk y this is issue, don't change\n",
    "        )\n",
    "\n",
    "        if _i._submit_state > 0:\n",
    "            n_job_running = run_cmds([f'squeue -u {_i.user} -h -t pending,running -r | wc -l'])\n",
    "            if n_job_running > cap:\n",
    "                exit(f'There are {n_job_running} on the submit cap is {cap}')\n",
    "\n",
    "            _slurm = Slurm(**_i.slurm.dict)\n",
    "\n",
    "            n_run, _i._submit_state = _i._submit_state, 0            \n",
    "            for _ in range(n_run):\n",
    "                _slurm.sbatch(_i.slurm.sbatch \n",
    "                + f'out_dir={(mkdir(_i.exp_path/\"out\"))} {_i.cmd} | tee $out_dir/py.out date \"+%B %V %T.%3N\" ')\n",
    "\n",
    "    @property\n",
    "    def cmd(_i,):\n",
    "        d = flat_dict(_i.dict)\n",
    "        return ' '.join([f' --{k}  {str(v)} ' for k,v in d.items()])\n",
    "\n",
    "    @property\n",
    "    def commit_id(_i,)->str:\n",
    "        process = run_cmds(['git log --pretty=format:%h -n 1'], cwd=_i.project_path)[0]\n",
    "        return process.stdout.decode('utf-8') \n",
    "\n",
    "    def submit(_i, sweep=False, commit_msg=None, cap=40):\n",
    "        commit_msg = commit_msg or _i.exp_id\n",
    "        _i._submit_state *= -1\n",
    "        if _i._submit_state > 0:\n",
    "            if sweep:\n",
    "                _i.sweep_id = wandb.sweep(\n",
    "                    env     = f'conda activate {_i.env};',\n",
    "                    sweep   = _i.sweep.dict, \n",
    "                    program = _i.run_path,\n",
    "                    project = _i.project,\n",
    "                    name    = _i.exp_name,\n",
    "                    run_cap = _i.sweep.n_sweep\n",
    "                )\n",
    "                _i._submit_state *= _i.sweep.n_sweep\n",
    "            local_out = run_cmds(['git add .', f'git commit -m {commit_msg}', 'git push'], cwd=_i.project_path)\n",
    "            server_out = run_cmds_server(_i.server, _i.user, f'python -u {_i.run_path} ' +_i.cmd, cwd=_i.server_project_path)\n",
    "\n",
    "def print_pyfig(d:dict):\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            print(f'{k}: ')\n",
    "            print_pyfig(v)\n",
    "        else:\n",
    "            print(k,v)\n",
    "\n",
    "c = Pyfig(wandb_mode='disabled', notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'af': 'tanh',\n",
      " 'commit_id': 'b78c668',\n",
      " 'data': {'b_size': 16,\n",
      "          'cache': False,\n",
      "          'channels': 1,\n",
      "          'dataset': 'fashion_mnist',\n",
      "          'image_size': 28},\n",
      " 'data_dir': PosixPath('/home/amawi/projects/data'),\n",
      " 'dtype': 'f32',\n",
      " 'entity': 'xmax1',\n",
      " 'env': 'dex',\n",
      " 'exp_id': 'NCscEnx',\n",
      " 'exp_name': 'junk',\n",
      " 'exp_path': PosixPath('/home/amawi/projects/hwat/exp/junk/NCscEnx'),\n",
      " 'git_branch': 'main',\n",
      " 'git_remote': 'origin',\n",
      " 'half_precision': True,\n",
      " 'iter_exp_dir': True,\n",
      " 'log_metric_step': 5,\n",
      " 'log_sample_step': 5,\n",
      " 'log_state_step': 10,\n",
      " 'model': {'dim': 64, 'dim_mults': (1, 2, 4)},\n",
      " 'n_device': 0,\n",
      " 'n_epoch': 20,\n",
      " 'n_layer': 3,\n",
      " 'n_step': 1000,\n",
      " 'opt': {'beta1': 0.9,\n",
      "         'beta2': 0.99,\n",
      "         'eps': 1e-08,\n",
      "         'loss': 'l1',\n",
      "         'lr': 0.001,\n",
      "         'optimizer': 'Adam'},\n",
      " 'project': 'hwat',\n",
      " 'project_cfg_dir': PosixPath('/home/amawi/projects/hwat/cfg'),\n",
      " 'project_exp_dir': PosixPath('/home/amawi/projects/hwat/exp'),\n",
      " 'project_path': PosixPath('/home/amawi/projects/hwat'),\n",
      " 'project_root': PosixPath('/home/amawi/projects'),\n",
      " 'run_path': PosixPath('/home/amawi/projects/hwat/run.py'),\n",
      " 'seed': 808017424,\n",
      " 'server': 'svol.fysik.dtu.dk',\n",
      " 'server_project_path': PosixPath('/home/amawi/projects/hwat'),\n",
      " 'slurm': {'cpus_per_task': 1,\n",
      "           'error': PosixPath('tmp/out/e-%j.err'),\n",
      "           'gres': 'gpu:RTX3090:1',\n",
      "           'job_name': 'junk',\n",
      "           'mail_type': 'FAIL',\n",
      "           'nodes': 1,\n",
      "           'ntasks': 8,\n",
      "           'output': PosixPath('tmp/out/o-%j.out'),\n",
      "           'partition': 'sm3090',\n",
      "           'sbatch': ' \\n'\n",
      "                     '            module purge \\n'\n",
      "                     '            source ~/.bashrc \\n'\n",
      "                     '            module load GCC \\n'\n",
      "                     '            module load CUDA/11.4.1 \\n'\n",
      "                     '            module load cuDNN/8.2.2.26-CUDA-11.4.1 \\n'\n",
      "                     '            conda activate dex \\n'\n",
      "                     '            export MKL_NUM_THREADS=1 \\n'\n",
      "                     '            export NUMEXPR_NUM_THREADS=1 \\n'\n",
      "                     '            export OMP_NUM_THREADS=1 \\n'\n",
      "                     '            export OPENBLAS_NUM_THREADS=1\\n'\n",
      "                     '            pwd\\n'\n",
      "                     '            nvidia-smi\\n'\n",
      "                     \"            mv_cmd = f'mv tmp/out/o-$SLURM_JOB_ID.out \"\n",
      "                     \"tmp/out/e-$SLURM_JOB_ID.err $out_dir' \\n\"\n",
      "                     '    ',\n",
      "           'time': '0-12:00:00'},\n",
      " 'submit': <bound method Pyfig.submit of <__main__.Pyfig object at 0x7f5b1ffdc3a0>>,\n",
      " 'sweep': {'method': 'random',\n",
      "           'metrics': {'goal': 'minimize', 'name': 'validation_loss'},\n",
      "           'n_sweep': 10,\n",
      "           'name': 'sweep',\n",
      "           'parameters': {'batch_size': {'values': [16, 32, 64]},\n",
      "                          'epoch': {'values': [5, 10, 15]},\n",
      "                          'lr': {'max': 0.1, 'min': 0.0001}},\n",
      "           'run_cap': 10,\n",
      "           'sweep_id': ''},\n",
      " 'user': 'amawi',\n",
      " 'wandb': {'entity': 'xmax1', 'job_type': 'training'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(c.dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4edb4a58a0461d84e636e9142615dc364f099c3851533546c18fbe9e367308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
